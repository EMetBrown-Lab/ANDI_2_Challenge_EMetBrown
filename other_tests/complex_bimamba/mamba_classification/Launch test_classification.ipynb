{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a4c625-1262-40f8-8bf6-10af6a1f0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_classification import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a047659-d3b7-4f0f-82cd-87efffa28f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_mamba_stacks = [1,2,4]\n",
    "dropouts = [0,0.05,0.1]\n",
    "learning_rate = [1e-3,1e-4]\n",
    "n_layer = [4,8,16,32]\n",
    "\n",
    "import itertools\n",
    "all_tests = list(itertools.product(bi_mamba_stacks, dropouts, learning_rate, n_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864cab03-d441-4d0d-813f-2cccc36e8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bd9a83-f5ae-43c4-bb28-ba822f61bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3405345-e421-4781-a29f-eb610b86a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9dd9e9-dd5a-4862-a5a7-9978d842a85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n",
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.432]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.259]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.198] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.181]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.257] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.237]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.405] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.605]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=1.01]  \n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.717]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.214] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.366]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.229] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.211]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.31]  \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.176]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.386] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.497] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.139] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.19]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.14]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.348]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.311] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.245]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:12<00:00,  6.03batch/s, loss=0.307] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.438]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.716] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.297] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.203] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.325]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s]  | 1/72 [41:35<49:13:06, 2495.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/800 [00:00<02:09,  6.15batch/s, loss=1.37]]2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.473]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.405]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.552] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.225]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.257] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.309] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.119] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.447] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.714] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.361] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=1.04]  \n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.252] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.505] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.161] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.299] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.264]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.337] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.837] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.221] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.0836]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.364] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.143]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.475] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.206] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.173] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.298]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.659] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.144]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.551] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                   | 3/72 [1:23:16<32:34:08, 1699.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.946]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.837]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.91] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.484]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.612]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.833]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.52] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.595]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.703]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.347]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.448]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.503]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.88batch/s, loss=0.432]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.88batch/s, loss=0.441]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.678]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.306]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.276] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.252]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.854] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.209]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.356]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.77] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.5]  \n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.439]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.282] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.214]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.48]  \n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.208]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=1.23]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.324]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]:05:09<26:57:34, 1448.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/800 [00:00<02:08,  6.23batch/s, loss=1.35]]2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=1.02] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.999]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.98] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.425]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.502]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.602]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.901]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=1.25] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.431]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.614]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.564]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.733]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.597]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.467]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.6]  \n",
      "Epoch 7: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.618]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.259]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.851]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.306]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.294]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.349]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.284]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.312]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.512]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.135] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.39] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.252] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.566] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.161] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.706] \n",
      "  0%|          | 0/800 [00:00<?, ?batch/s]| 7/72 [2:46:58<26:23:54, 1462.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▉         | 75/800 [00:12<02:01,  5.99batch/s, loss=1.03] .95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.264]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.284]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.47]  \n",
      "Epoch 1: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.548]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.787] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.88batch/s, loss=0.265]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.161] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.268]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:13<00:00,  6.00batch/s, loss=0.498] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.37] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.114] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.262]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.262] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.206]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.218] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.907]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=1.04]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.558]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.46]  \n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.464]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.417] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.208]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.328] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.485]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.452] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.321] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.365] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.263] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.395] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/800 [00:00<02:16,  5.87batch/s, loss=1.43]57]11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=1.12] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.308]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:19<00:00,  5.71batch/s, loss=0.405] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.341]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.624] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.18] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.817] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.533] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.34]  \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.598] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.311] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.611]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.362] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.593]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.394] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.355]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.296] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.251]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.495] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.412] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=1.21]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.324]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.424] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.207]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.314] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.185] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.296] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.407]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.522] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.242]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 11/72 [4:11:52<23:28:24, 1385.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]batch/s, loss=1.55]44.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=1.05]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=1.19]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.719]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.828]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.486]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.629]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.436]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.564]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.82] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.407]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.305]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.574]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.68] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.459]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.407]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.921]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.306]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.374]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.456] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.394]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.277]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.538]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.273] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.358]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.382] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.211]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.388] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:12<00:00,  6.04batch/s, loss=0.411]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.494]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.467]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 13/72 [4:54:14<23:30:06, 1434.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/800 [00:00<02:11,  6.09batch/s, loss=1.45]]6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:08<00:00,  6.21batch/s, loss=0.921]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=1.19]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:08<00:00,  6.20batch/s, loss=0.616]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.773]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.417]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.569]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.626]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.539]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:08<00:00,  6.20batch/s, loss=0.598]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.478]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.516]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.828]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.263]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.409]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.214]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.399]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.665]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.59] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.285]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.401]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.287]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.419]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.366] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.194] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.313]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.671]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.158]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.209] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.589] \n",
      " 21%|███████▌                            | 15/72 [5:34:27<22:35:09, 1426.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.194] \n",
      "Epoch 0:  92%|█████████▏| 734/800 [02:00<00:10,  6.15batch/s, loss=0.493]09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.176]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.502]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.494]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.523]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=1.05] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.452]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.34] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.304] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.517]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.173] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.286]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.691] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.612]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.774] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.628]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.803]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.321]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.31]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.807]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.392]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.259]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.277] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.584]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:12<00:00,  6.06batch/s, loss=0.359] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.963]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.47] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.308]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.647] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.296]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 17/72 [6:15:12<21:43:32, 1422.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.404]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.34] \n",
      "Epoch 1:  24%|██▍       | 195/800 [00:31<01:37,  6.22batch/s, loss=0.416]00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.396]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.298]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.377]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.467]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.378]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.304]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.376]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.504]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=1.25]  \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.472]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.353]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.435]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.91]  \n",
      "Epoch 6: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.624]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.205]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.225]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.313]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.88batch/s, loss=0.804] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.447]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.345]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.194] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.319] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:11<00:00,  6.11batch/s, loss=0.693]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.465]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.278]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.33] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.36] \n",
      "Epoch 13:  30%|███       | 243/800 [00:41<01:31,  6.09batch/s, loss=0.174]6s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.699]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=1.19]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.491]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.598]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 20/72 [7:00:48<15:37:01, 1081.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.908]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.504]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.542]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.333]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.51] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.348]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.56] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.519]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.395]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.517]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.57] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.668]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.538]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.296]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.574]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.294]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:12<00:00,  6.04batch/s, loss=0.375]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.464]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.504]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.788]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.401]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.43] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.274]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.287]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.32]]\n",
      "Epoch 12:  63%|██████▎   | 504/800 [01:27<00:50,  5.82batch/s, loss=0.86] 1s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.628]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:12<00:00,  6.02batch/s, loss=0.956]]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.383]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.581]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.35] \n",
      "Epoch 2:  75%|███████▌  | 602/800 [01:38<00:32,  6.06batch/s, loss=0.723]19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.62] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.906]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:12<00:00,  6.06batch/s, loss=0.681]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:11<00:00,  6.11batch/s, loss=0.613]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.377]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.386]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.513]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.773]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:13<00:00,  6.00batch/s, loss=0.767]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.61] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:12<00:00,  6.03batch/s, loss=0.511]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.409]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:12<00:00,  6.02batch/s, loss=0.241]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.357]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.636]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.368]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:12<00:00,  6.03batch/s, loss=0.388]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.256] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.629]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.344]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:12<00:00,  6.03batch/s, loss=0.451]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.282]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:11<00:00,  6.07batch/s, loss=0.279]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.28] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:12<00:00,  6.04batch/s, loss=0.513]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s].74batch/s, loss=0.479]4s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.263]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.302] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.88batch/s, loss=0.728]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.103] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.589]\n",
      "Epoch 2:  91%|█████████ | 728/800 [02:04<00:12,  5.87batch/s, loss=0.201]52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.195] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.276] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.141] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.187] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.365] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.177] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.21]  \n",
      "Epoch 3: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.296] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.29]  \n",
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.773] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.158] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.0963]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.319]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.0991]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.545]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.272] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.182] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.389] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.135] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.336] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.632] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.282] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.258] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.27]  \n",
      "Epoch 11:  76%|███████▋  | 610/800 [01:47<00:32,  5.76batch/s, loss=0.264]9s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.623] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.0944] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.149] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.293]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:20<00:00,  5.67batch/s, loss=0.729] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.366]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.441] \n",
      "Epoch 3:  55%|█████▌    | 441/800 [01:16<01:03,  5.68batch/s, loss=0.582]77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.745] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.596] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.56]  \n",
      "Epoch 1: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.208] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.276] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.273] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.451] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.441] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.383] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.167] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.25]  \n",
      "Epoch 5: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.161] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.265] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.89] ] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.67batch/s, loss=0.249] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.443]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.355] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.644]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.29]  \n",
      "Epoch 9: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.344]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.304] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.255] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.309] \n",
      "Epoch 11:  56%|█████▋    | 451/800 [01:18<01:05,  5.31batch/s, loss=0.861]7s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.444] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=1.21]2] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.555] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.699]1]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.153] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.579]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.734] \n",
      "Epoch 3:  66%|██████▌   | 528/800 [01:31<00:47,  5.74batch/s, loss=0.529]45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.221]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=1.17]]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.575]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.995]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.698]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.506]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.257]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.651]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.505]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.299]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.416]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.564] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.216] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.212]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.399] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.195]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.322] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.587]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.291] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.246]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.35]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.344] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.257] \n",
      "Epoch 11:  59%|█████▉    | 471/800 [01:22<00:56,  5.79batch/s, loss=0.212]9s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.662] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=1]    ] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.286] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.612]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.139] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.61] ] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.239] \n",
      "Epoch 3:  84%|████████▍ | 676/800 [01:53<00:21,  5.89batch/s, loss=0.643]65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.278]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=1.24]]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.218]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.709]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.181]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.593]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.357]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.479]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.318]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.559] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.468] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.317] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.295]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.93batch/s, loss=0.142] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.125] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.199] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.534]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.305] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.617] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.482] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.565]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.318] \n",
      "Epoch 10:  80%|███████▉  | 638/800 [01:54<00:28,  5.62batch/s, loss=0.543]3s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.343] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.63] ] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.351] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.321]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.149] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.206]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.2]   \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.28]6] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.565] \n",
      "Epoch 4:  68%|██████▊   | 541/800 [01:32<00:42,  6.08batch/s, loss=0.68] 00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.13]] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.315] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.289] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.167] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.245] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=2.71]  \n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.29]  \n",
      "Epoch 3: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.244] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.25]  \n",
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.171] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.204] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.137]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.214] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.165]  \n",
      "Epoch 11: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.217] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.506]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=1.22]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.187]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.258] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.921]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.146]\n",
      "Epoch 10:   4%|▍         | 34/800 [00:06<02:17,  5.56batch/s, loss=0.796]73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.191]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.454]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.11] ] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.426] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.281]  \n",
      "Epoch 12: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.366]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.661]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.212] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.265]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.343] \n",
      "Epoch 5:  35%|███▌      | 281/800 [00:47<01:26,  6.03batch/s, loss=0.444]78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.283] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.575] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.279] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.261] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.223] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.336] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.802] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.188] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.285] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=1.27]1] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.143] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.345]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.193] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.31] ] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.184] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.217]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.305] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.492]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.318] \n",
      "Epoch 9:  24%|██▍       | 192/800 [00:33<01:44,  5.82batch/s, loss=0.204]38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.314] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=1.07] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.256] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.583]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=1.08]  \n",
      "Epoch 2: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.453]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.365] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.41] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.284] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:18<00:00,  5.80batch/s, loss=0.909]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.534] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.647]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]batch/s, loss=0.285]7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.625]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=1.18]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.276]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.95] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:16<00:00,  5.87batch/s, loss=0.217]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.599]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.228]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.61] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.299] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.982]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.386] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.747]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.177]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.356]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.346] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.439]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.198] \n",
      "Epoch 8:  82%|████████▏ | 654/800 [01:56<00:24,  5.86batch/s, loss=0.253]40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.249]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=1.23]]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.397] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.533]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:25<00:00,  5.50batch/s, loss=0.266] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.389]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.515] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.524]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.223] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.708]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.449]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.441]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.22] \n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]54batch/s, loss=0.403]03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.311]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=1.03] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.466]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.603]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.416]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.988]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.658]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.404]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.546]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.518]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.562]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:22<00:00,  5.59batch/s, loss=0.439]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.306]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.53] ] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=1.24] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.521]  \n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.0997]\n",
      "Epoch 0:   0%|          | 1/800 [00:00<02:14,  5.95batch/s, loss=1.39]4].87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.242]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.544]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:25<00:00,  5.48batch/s, loss=0.29]  \n",
      "Epoch 1: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.175]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:26<00:00,  5.47batch/s, loss=0.297] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.237]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.307]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:24<00:00,  5.53batch/s, loss=0.42] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.284]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:25<00:00,  5.49batch/s, loss=0.249]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.156]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:25<00:00,  5.49batch/s, loss=0.21]  \n",
      "Epoch 6: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.376]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.511] \n",
      "Epoch 7:  12%|█▏        | 98/800 [00:17<02:09,  5.43batch/s, loss=0.348].22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.296] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:26<00:00,  5.46batch/s, loss=0.708]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:24<00:00,  5.53batch/s, loss=0.206] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:27<00:00,  5.43batch/s, loss=0.424] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.45]  \n",
      "Epoch 2: 100%|██████████| 800/800 [02:26<00:00,  5.46batch/s, loss=0.144]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:25<00:00,  5.49batch/s, loss=0.167] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:28<00:00,  5.38batch/s, loss=0.256] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:24<00:00,  5.52batch/s, loss=0.257] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:27<00:00,  5.41batch/s, loss=0.694] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:25<00:00,  5.50batch/s, loss=0.17]  \n",
      "Epoch 5: 100%|██████████| 800/800 [02:28<00:00,  5.38batch/s, loss=0.698] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.169] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:27<00:00,  5.42batch/s, loss=0.127] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.276] \n",
      "Epoch 7:  88%|████████▊ | 705/800 [02:09<00:17,  5.30batch/s, loss=0.794]16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 800/800 [02:27<00:00,  5.42batch/s, loss=0.321]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.233] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:27<00:00,  5.43batch/s, loss=0.365] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.274] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:25<00:00,  5.51batch/s, loss=0.335] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.986]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.281] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.425]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.932] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.183] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.152] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.169]]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.578] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.80batch/s, loss=0.468]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:25<00:00,  5.51batch/s, loss=0.25]  \n",
      "Epoch 7:  86%|████████▌ | 687/800 [01:59<00:18,  6.03batch/s, loss=0.167]60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.139] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:25<00:00,  5.48batch/s, loss=0.334] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.80batch/s, loss=0.333] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:28<00:00,  5.38batch/s, loss=0.34]  \n",
      "Epoch 9: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.181] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:26<00:00,  5.46batch/s, loss=0.574]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=1.19] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:26<00:00,  5.48batch/s, loss=0.591]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.164]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.285] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:25<00:00,  5.49batch/s, loss=0.273]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.603] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:25<00:00,  5.48batch/s, loss=0.405]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.226] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:25<00:00,  5.51batch/s, loss=0.502]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s]43/72 [15:22:57<10:27:37, 1298.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.883] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.265]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:19<00:00,  5.71batch/s, loss=0.842] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:25<00:00,  5.50batch/s, loss=1.18]  \n",
      "Epoch 2: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.575] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:26<00:00,  5.47batch/s, loss=0.257]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.506]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.392] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.313]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:26<00:00,  5.48batch/s, loss=0.853] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.286]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:26<00:00,  5.46batch/s, loss=0.188] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.283]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:26<00:00,  5.44batch/s, loss=0.238] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.246]  \n",
      "Epoch 14: 100%|██████████| 800/800 [02:27<00:00,  5.44batch/s, loss=0.415]\n",
      "Epoch 8:  70%|███████   | 563/800 [01:38<00:40,  5.90batch/s, loss=0.568]24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.407]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:26<00:00,  5.48batch/s, loss=1.03] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.774]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.596]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.195]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.706]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.204]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.553]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.163]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.35] ]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.151] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.46] ]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.252] \n",
      "Epoch 6:  31%|███       | 246/800 [00:44<01:40,  5.52batch/s, loss=0.187]82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.431]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=1.22]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.59batch/s, loss=0.232]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.779]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.623]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.521]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.164]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.807]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.211]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.911]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.749]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.37] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:23<00:00,  5.59batch/s, loss=0.284]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.345]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:23<00:00,  5.57batch/s, loss=0.499]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.329]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:24<00:00,  5.55batch/s, loss=0.232] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.537]\n",
      "Epoch 9:   0%|          | 4/800 [00:00<02:21,  5.62batch/s, loss=0.649]1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.47] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=1.08]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.356]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:26<00:00,  5.48batch/s, loss=0.63] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.246] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:26<00:00,  5.47batch/s, loss=0.469]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.359] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:25<00:00,  5.51batch/s, loss=0.818]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.418]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:26<00:00,  5.48batch/s, loss=0.764]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.76] \n",
      "Epoch 5:  86%|████████▌ | 688/800 [02:07<00:21,  5.24batch/s, loss=0.503]82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 800/800 [02:27<00:00,  5.41batch/s, loss=0.427]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:27<00:00,  5.44batch/s, loss=0.375] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.482]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:30<00:00,  5.32batch/s, loss=0.112] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:29<00:00,  5.36batch/s, loss=0.554]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:29<00:00,  5.34batch/s, loss=0.619] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:27<00:00,  5.41batch/s, loss=0.377] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:29<00:00,  5.35batch/s, loss=0.332] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.349]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:32<00:00,  5.26batch/s, loss=0.899]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:28<00:00,  5.38batch/s, loss=0.288]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:29<00:00,  5.35batch/s, loss=0.189]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:26<00:00,  5.44batch/s, loss=0.212]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:29<00:00,  5.36batch/s, loss=0.223]]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:27<00:00,  5.42batch/s, loss=0.512]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:29<00:00,  5.33batch/s, loss=0.242]]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:27<00:00,  5.41batch/s, loss=0.358]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:30<00:00,  5.32batch/s, loss=0.288]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:26<00:00,  5.45batch/s, loss=0.533]\n",
      "Epoch 9:  33%|███▎      | 267/800 [00:49<01:42,  5.19batch/s, loss=0.666]82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 800/800 [02:30<00:00,  5.31batch/s, loss=0.225] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:37<00:00,  5.07batch/s, loss=0.252]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:30<00:00,  5.31batch/s, loss=0.193] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:35<00:00,  5.16batch/s, loss=0.227]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:28<00:00,  5.38batch/s, loss=0.192] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:35<00:00,  5.16batch/s, loss=0.186]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:31<00:00,  5.27batch/s, loss=0.155] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:35<00:00,  5.14batch/s, loss=0.199]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:30<00:00,  5.32batch/s, loss=0.249] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:35<00:00,  5.14batch/s, loss=0.327]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:29<00:00,  5.34batch/s, loss=0.395] \n",
      "Epoch 5:  62%|██████▏   | 494/800 [01:36<00:58,  5.22batch/s, loss=0.132]86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 800/800 [02:36<00:00,  5.13batch/s, loss=0.322] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:29<00:00,  5.37batch/s, loss=0.726] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:36<00:00,  5.11batch/s, loss=0.16]  \n",
      "Epoch 1: 100%|██████████| 800/800 [02:29<00:00,  5.35batch/s, loss=0.245] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:36<00:00,  5.10batch/s, loss=0.323] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:30<00:00,  5.31batch/s, loss=0.586] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:36<00:00,  5.11batch/s, loss=0.184] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:30<00:00,  5.32batch/s, loss=0.762] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:36<00:00,  5.11batch/s, loss=0.296] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:31<00:00,  5.28batch/s, loss=0.282]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:36<00:00,  5.11batch/s, loss=0.197] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:33<00:00,  5.22batch/s, loss=0.379] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:36<00:00,  5.13batch/s, loss=0.281] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:33<00:00,  5.23batch/s, loss=0.229] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:37<00:00,  5.09batch/s, loss=0.177] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:34<00:00,  5.19batch/s, loss=0.241] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:35<00:00,  5.14batch/s, loss=0.358] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:30<00:00,  5.33batch/s, loss=0.144] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:29<00:00,  5.35batch/s, loss=0.311] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.209] \n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 50/72 [18:05:22<8:52:09, 1451.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:28<00:00,  5.39batch/s, loss=0.107]  \n",
      "Epoch 10: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.822] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.25] ] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.591] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.144]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.211] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.223]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.363] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.448]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.377]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]batch/s, loss=0.225]9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=1.34]] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.182]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.773] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.198]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.606] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.304] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.42]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.894] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.474] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.22]  \n",
      "Epoch 5: 100%|██████████| 800/800 [02:17<00:00,  5.80batch/s, loss=0.265]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.148] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.277]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.286] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.406]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.15]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.556]8]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.352] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.153]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.401] \n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s].60batch/s, loss=0.421]3s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.297] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.979]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=1.09]  \n",
      "Epoch 1: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.666]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.148] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.603]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.393] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.528]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.504] \n",
      "Epoch 4:  92%|█████████▏| 738/800 [02:10<00:10,  5.75batch/s, loss=0.69] 15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.626]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=1.33]]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.611]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.885]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.289]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:16<00:00,  5.84batch/s, loss=0.567]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.224]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.821]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.878]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.744]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.14] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.315]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.555] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.744]  \n",
      "Epoch 11: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.425]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.19] ] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.141] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.392]]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.288] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:19<00:00,  5.75batch/s, loss=0.183]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.352] \n",
      "Epoch 10:  68%|██████▊   | 547/800 [01:34<00:43,  5.80batch/s, loss=0.29] 3s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.445] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=1.03] ] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.387] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.623]3]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:19<00:00,  5.73batch/s, loss=0.332] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.454]  \n",
      "Epoch 13: 100%|██████████| 800/800 [02:19<00:00,  5.72batch/s, loss=0.437] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.434]] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:18<00:00,  5.77batch/s, loss=0.633] \n",
      "Epoch 4:  36%|███▋      | 292/800 [00:52<01:33,  5.46batch/s, loss=0.87].49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 800/800 [02:23<00:00,  5.58batch/s, loss=0.363]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:20<00:00,  5.70batch/s, loss=0.502]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.704]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.28] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.722]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.908]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:23<00:00,  5.56batch/s, loss=0.702] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.236]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.283] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.297] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:24<00:00,  5.53batch/s, loss=0.261] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:18<00:00,  5.76batch/s, loss=0.177]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:25<00:00,  5.51batch/s, loss=0.422] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:18<00:00,  5.78batch/s, loss=0.201] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.186]  \n",
      "Epoch 11: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.178]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.104]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:24<00:00,  5.53batch/s, loss=0.381] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.427]] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:24<00:00,  5.54batch/s, loss=0.303] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.211] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:22<00:00,  5.60batch/s, loss=0.246] \n",
      "Epoch 11:  24%|██▍       | 192/800 [00:32<01:45,  5.74batch/s, loss=0.259]1s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.415] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.305] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:18<00:00,  5.79batch/s, loss=0.183] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.193]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.248] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.289]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.159] \n",
      "Epoch 3:  86%|████████▋ | 690/800 [02:01<00:19,  5.67batch/s, loss=0.792]38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.247]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.332] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.284] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.743] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:21<00:00,  5.63batch/s, loss=0.215] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.289] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.308] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.367] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.318] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.22]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.798] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.251] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.469] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.42]5]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.35]  \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.463]]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.712] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=1.03]  \n",
      "Epoch 12: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.558] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.57]  \n",
      "Epoch 13: 100%|██████████| 800/800 [02:22<00:00,  5.62batch/s, loss=0.459] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.181] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:22<00:00,  5.61batch/s, loss=0.272] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.156] \n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 58/72 [21:00:20<5:32:18, 1424.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:20<00:00,  5.69batch/s, loss=0.369]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.469] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.361]  \n",
      "Epoch 13: 100%|██████████| 800/800 [02:17<00:00,  5.82batch/s, loss=0.441]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.276] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.243]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]1:08:57<4:09:35, 1151.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=1.17]  \n",
      "Epoch 3: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.202]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.873] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.386]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.65]]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.122] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.829] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.181] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.591] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:22<00:00,  5.59batch/s, loss=0.522] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:16<00:00,  5.85batch/s, loss=0.628] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.135] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.732] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.219] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:17<00:00,  5.83batch/s, loss=0.769]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.24]  \n",
      "Epoch 8: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=0.646]] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.363] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:17<00:00,  5.84batch/s, loss=0.458]] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.277] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.427] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.0737]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:16<00:00,  5.86batch/s, loss=0.502] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.275] \n",
      "Epoch 12:  59%|█████▉    | 470/800 [01:20<00:55,  5.99batch/s, loss=0.429]7s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.548]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=1.22]1]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.454]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:20<00:00,  5.67batch/s, loss=0.948]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.3]  \n",
      "Epoch 2:  54%|█████▎    | 428/800 [01:15<01:04,  5.75batch/s, loss=0.72] 22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.613]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=1.23]]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.589]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.897]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.922]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.611]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:21<00:00,  5.65batch/s, loss=0.253]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.597]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.924]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.6]  \n",
      "Epoch 7: 100%|██████████| 800/800 [02:20<00:00,  5.68batch/s, loss=0.143]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.442]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:22<00:00,  5.63batch/s, loss=0.349]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.366]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:19<00:00,  5.74batch/s, loss=0.298]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:16<00:00,  5.88batch/s, loss=0.334]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:20<00:00,  5.71batch/s, loss=0.546] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.327]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.277] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.495]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:21<00:00,  5.67batch/s, loss=0.222] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:15<00:00,  5.90batch/s, loss=0.359]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.506] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:21<00:00,  5.66batch/s, loss=0.325]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.294]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:21<00:00,  5.64batch/s, loss=0.185]\n",
      "Epoch 0:   0%|          | 0/800 [00:00<?, ?batch/s]97batch/s, loss=0.54] 68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.539]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:17<00:00,  5.81batch/s, loss=1.06]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.768]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.667]\n",
      "  0%|          | 0/800 [00:00<?, ?batch/s] 63/72 [22:32:31<2:45:50, 1105.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:12<00:00,  6.04batch/s, loss=0.652]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.567]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.232]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.523]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=0.305]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.63] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:11<00:00,  6.11batch/s, loss=0.194]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.386]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.962]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.455]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.254] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.562]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.713]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.622]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.306] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.549]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:12<00:00,  6.05batch/s, loss=0.544]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.521]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:11<00:00,  6.10batch/s, loss=0.32]  \n",
      "Epoch 11: 100%|██████████| 800/800 [02:13<00:00,  6.01batch/s, loss=0.281]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.397] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.437]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.178] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.514]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.515] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.879]\n",
      "Epoch 13:  60%|██████    | 480/800 [01:18<00:49,  6.47batch/s, loss=0.476]2s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.531] \n",
      "Epoch 0: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.327]]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.488] \n",
      "Epoch 1:  56%|█████▌    | 448/800 [01:15<00:58,  6.01batch/s, loss=0.173]54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 800/800 [02:15<00:00,  5.91batch/s, loss=0.459]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:09<00:00,  6.20batch/s, loss=0.245]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.308] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:07<00:00,  6.26batch/s, loss=0.245]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.736] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:07<00:00,  6.26batch/s, loss=0.38] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.186] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:08<00:00,  6.24batch/s, loss=0.268] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.839]]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:08<00:00,  6.25batch/s, loss=0.24]  \n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.252] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:07<00:00,  6.28batch/s, loss=0.261] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.309] \n",
      "Epoch 6: 100%|██████████| 800/800 [02:08<00:00,  6.23batch/s, loss=0.212]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:15<00:00,  5.93batch/s, loss=0.205] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:08<00:00,  6.21batch/s, loss=0.264]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:08<00:00,  6.21batch/s, loss=0.254] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.215]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:08<00:00,  6.23batch/s, loss=0.428]] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=1.14] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:09<00:00,  6.20batch/s, loss=0.367] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.346]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:08<00:00,  6.23batch/s, loss=0.156] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.199]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:07<00:00,  6.25batch/s, loss=0.22]  \n",
      "Epoch 13: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.195] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:08<00:00,  6.24batch/s, loss=0.224] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.326]\n",
      " 92%|█████████████████████████████████   | 66/72 [23:50:21<2:22:32, 1425.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 800/800 [02:08<00:00,  6.23batch/s, loss=0.285] \n",
      "Epoch 0:  88%|████████▊ | 700/800 [01:57<00:16,  5.96batch/s, loss=0.294]95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.153]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.746] \n",
      "Epoch 1: 100%|██████████| 800/800 [02:14<00:00,  5.97batch/s, loss=0.214]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:11<00:00,  6.09batch/s, loss=1.04] \n",
      "Epoch 2: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.195]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.715] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.314]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.441] \n",
      "Epoch 4: 100%|██████████| 800/800 [02:14<00:00,  5.94batch/s, loss=0.241]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.593]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.19] \n",
      "Epoch 5: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.693]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:14<00:00,  5.95batch/s, loss=0.238]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.385] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:14<00:00,  5.93batch/s, loss=0.705]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.596]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.333]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:09<00:00,  6.20batch/s, loss=1.12] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.191] \n",
      "Epoch 9: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.384]]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:14<00:00,  5.96batch/s, loss=0.272] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:11<00:00,  6.08batch/s, loss=0.327]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:15<00:00,  5.89batch/s, loss=0.293]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:10<00:00,  6.14batch/s, loss=0.421]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:15<00:00,  5.92batch/s, loss=0.782] \n",
      "Epoch 12: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.544]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.338] \n",
      "Epoch 13: 100%|██████████| 800/800 [02:10<00:00,  6.11batch/s, loss=0.476]\n",
      "Epoch 14: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.133] \n",
      "Epoch 14:  99%|█████████▉| 795/800 [02:09<00:00,  6.22batch/s, loss=0.798]3s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 800/800 [02:10<00:00,  6.12batch/s, loss=0.166]\n",
      "Epoch 0:  23%|██▎       | 187/800 [00:30<01:43,  5.93batch/s, loss=1.11].46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 800/800 [02:11<00:00,  6.06batch/s, loss=0.785]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=1.04]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.469]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.954]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.522]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.521]\n",
      "Epoch 3: 100%|██████████| 800/800 [02:12<00:00,  6.04batch/s, loss=0.78] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:10<00:00,  6.13batch/s, loss=0.694]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.421]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.878]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:13<00:00,  5.98batch/s, loss=0.414]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.557]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.741]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=1.02] \n",
      "Epoch 7: 100%|██████████| 800/800 [02:11<00:00,  6.06batch/s, loss=0.534]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:13<00:00,  6.00batch/s, loss=0.458]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:09<00:00,  6.20batch/s, loss=0.55] \n",
      "Epoch 8: 100%|██████████| 800/800 [02:13<00:00,  6.01batch/s, loss=0.297]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:09<00:00,  6.18batch/s, loss=0.611]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.225]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:09<00:00,  6.16batch/s, loss=0.297]\n",
      "Epoch 10: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.37] \n",
      "Epoch 11: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.325]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.704]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:10<00:00,  6.15batch/s, loss=0.637]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:13<00:00,  5.99batch/s, loss=0.373]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:09<00:00,  6.17batch/s, loss=0.374]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:13<00:00,  6.01batch/s, loss=0.25] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:09<00:00,  6.19batch/s, loss=0.478]\n",
      "Epoch 14:  90%|█████████ | 724/800 [02:01<00:12,  5.96batch/s, loss=0.472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing gpu Mamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 800/800 [02:13<00:00,  5.97batch/s, loss=0.491]\n",
      "Epoch 0: 100%|██████████| 800/800 [02:07<00:00,  6.26batch/s, loss=1.25].76s/it]\n",
      "Epoch 1: 100%|██████████| 800/800 [02:06<00:00,  6.34batch/s, loss=0.932]\n",
      "Epoch 2: 100%|██████████| 800/800 [02:05<00:00,  6.37batch/s, loss=0.59] \n",
      "Epoch 3: 100%|██████████| 800/800 [02:06<00:00,  6.35batch/s, loss=0.258]\n",
      "Epoch 4: 100%|██████████| 800/800 [02:05<00:00,  6.37batch/s, loss=0.381]\n",
      "Epoch 5: 100%|██████████| 800/800 [02:05<00:00,  6.38batch/s, loss=0.701]\n",
      "Epoch 6: 100%|██████████| 800/800 [02:04<00:00,  6.43batch/s, loss=0.538]\n",
      "Epoch 7: 100%|██████████| 800/800 [02:06<00:00,  6.32batch/s, loss=0.254]\n",
      "Epoch 8: 100%|██████████| 800/800 [02:06<00:00,  6.34batch/s, loss=0.227]\n",
      "Epoch 9: 100%|██████████| 800/800 [02:05<00:00,  6.38batch/s, loss=0.66] \n",
      "Epoch 10: 100%|██████████| 800/800 [02:05<00:00,  6.37batch/s, loss=0.574]\n",
      "Epoch 11: 100%|██████████| 800/800 [02:06<00:00,  6.34batch/s, loss=0.321]\n",
      "Epoch 12: 100%|██████████| 800/800 [02:06<00:00,  6.35batch/s, loss=0.409]\n",
      "Epoch 13: 100%|██████████| 800/800 [02:06<00:00,  6.34batch/s, loss=0.32] \n",
      "Epoch 14: 100%|██████████| 800/800 [02:06<00:00,  6.34batch/s, loss=0.17] \n",
      "100%|██████████████████████████████████████| 72/72 [25:50:46<00:00, 1292.31s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "with Pool(processes=2) as pool:\n",
    "\n",
    "   # results = pool.map(train, all_tests[:2])\n",
    "    results = list(tqdm.tqdm(pool.imap(train, all_tests), total=len(all_tests)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37ea12a-507c-4d93-a376-fecf675db8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5888006014376879,\n",
       "   0.3554922965914011,\n",
       "   0.34230560788884756,\n",
       "   0.33412268513347954,\n",
       "   0.3319829440210015,\n",
       "   0.3403720904048532,\n",
       "   0.34275523278862235,\n",
       "   0.3344514450710267,\n",
       "   0.33335853384807707,\n",
       "   0.3324003600003198,\n",
       "   0.33582407848909496,\n",
       "   0.3400953121297061,\n",
       "   0.3281318891514093,\n",
       "   0.3422884578583762,\n",
       "   0.3369119368027896],\n",
       "  'running_test_loss': [0.27506891343742607,\n",
       "   0.23262566270306706,\n",
       "   0.20289337852969766,\n",
       "   0.21422394087538124,\n",
       "   0.19481351343914866,\n",
       "   0.21146572140976785,\n",
       "   0.20782663073390722,\n",
       "   0.22326436176896094,\n",
       "   0.23523318223655224,\n",
       "   0.22333504000678658,\n",
       "   0.21456787072122097,\n",
       "   0.1997729044035077,\n",
       "   0.1848162528127432,\n",
       "   0.24421838998794557,\n",
       "   0.18587596954777838]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.7516755221225321,\n",
       "   0.33859937395900486,\n",
       "   0.34002037869766355,\n",
       "   0.33725533648394046,\n",
       "   0.3299141713604331,\n",
       "   0.3437059641256928,\n",
       "   0.33531841898337006,\n",
       "   0.33401638112962245,\n",
       "   0.33840975239872934,\n",
       "   0.3313935723807663,\n",
       "   0.3548906316608191,\n",
       "   0.3240851204423234,\n",
       "   0.36010152406990525,\n",
       "   0.33067667167168113,\n",
       "   0.3329013909492642],\n",
       "  'running_test_loss': [0.27248305693268776,\n",
       "   0.22676004035398364,\n",
       "   0.24235557343810796,\n",
       "   0.19371340040117502,\n",
       "   0.2072353355959058,\n",
       "   0.20609674464911223,\n",
       "   0.23440010253340005,\n",
       "   0.23466414246708156,\n",
       "   0.21985485283657907,\n",
       "   0.24542181534692645,\n",
       "   0.21615822995081543,\n",
       "   0.1709692324139178,\n",
       "   0.20300849478691815,\n",
       "   0.20077851764857768,\n",
       "   0.21082995127886534]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5779716163035482,\n",
       "   0.3509221822349355,\n",
       "   0.3482498622359708,\n",
       "   0.3516929968027398,\n",
       "   0.3355299791973084,\n",
       "   0.3443296680040657,\n",
       "   0.32934453298337757,\n",
       "   0.3360131909884512,\n",
       "   0.341144413696602,\n",
       "   0.3355179233197123,\n",
       "   0.3213426942937076,\n",
       "   0.3404370898613706,\n",
       "   0.34740452163852753,\n",
       "   0.34720486476551743,\n",
       "   0.3500158286187798],\n",
       "  'running_test_loss': [0.25808118730783464,\n",
       "   0.22008854148909449,\n",
       "   0.19595270598307252,\n",
       "   0.21887234153226018,\n",
       "   0.25201508490368724,\n",
       "   0.21868348591029643,\n",
       "   0.21709209797903894,\n",
       "   0.22168756805360318,\n",
       "   0.17929244644939898,\n",
       "   0.24252642320469023,\n",
       "   0.19766160253435372,\n",
       "   0.18584726681932806,\n",
       "   0.23187330529093741,\n",
       "   0.1945481773465872,\n",
       "   0.2214895662292838]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6646083248779178,\n",
       "   0.36242084235418587,\n",
       "   0.34733096151612697,\n",
       "   0.342349360762164,\n",
       "   0.3405856608692557,\n",
       "   0.36275221841409805,\n",
       "   0.3344040544284508,\n",
       "   0.3283998707868159,\n",
       "   0.3265798933105543,\n",
       "   0.343252173261717,\n",
       "   0.3426001371257007,\n",
       "   0.3434892607992515,\n",
       "   0.3352152031380683,\n",
       "   0.32769188173115255,\n",
       "   0.3474877777416259],\n",
       "  'running_test_loss': [0.31795698426663876,\n",
       "   0.22084271013736725,\n",
       "   0.2512959556654096,\n",
       "   0.22275001920759677,\n",
       "   0.20553525166586042,\n",
       "   0.2237027601338923,\n",
       "   0.21016473917290568,\n",
       "   0.2190633288025856,\n",
       "   0.2265859978273511,\n",
       "   0.21824600199237465,\n",
       "   0.22114113433286547,\n",
       "   0.20495586697012186,\n",
       "   0.22656956505030393,\n",
       "   0.21062049619853496,\n",
       "   0.19314817188307642]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.0527766297012568,\n",
       "   0.7101793187484146,\n",
       "   0.5865810946002603,\n",
       "   0.5442603967152536,\n",
       "   0.5075224244035781,\n",
       "   0.4705794206634164,\n",
       "   0.44744047824293376,\n",
       "   0.42546830960549414,\n",
       "   0.41359531970694663,\n",
       "   0.40330544001422824,\n",
       "   0.401987186698243,\n",
       "   0.393917724583298,\n",
       "   0.38097241457551717,\n",
       "   0.37312078340910376,\n",
       "   0.3596093096211553],\n",
       "  'running_test_loss': [0.8297069945931435,\n",
       "   0.5590081976354122,\n",
       "   0.4579453856498003,\n",
       "   0.41876929223537446,\n",
       "   0.37397229976952073,\n",
       "   0.35390739306807517,\n",
       "   0.3162195086106658,\n",
       "   0.30554399125278,\n",
       "   0.3196670358628035,\n",
       "   0.2629802237823606,\n",
       "   0.2695831409096718,\n",
       "   0.2745467498898506,\n",
       "   0.27629261184483767,\n",
       "   0.24628251291811465,\n",
       "   0.2441595532745123]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2134987326711417,\n",
       "   0.770988298356533,\n",
       "   0.6411252123489976,\n",
       "   0.6034300420060754,\n",
       "   0.5896088382788003,\n",
       "   0.5673920453339815,\n",
       "   0.5639974456839263,\n",
       "   0.531332709826529,\n",
       "   0.5101180908828974,\n",
       "   0.4762340041622519,\n",
       "   0.44509609690867363,\n",
       "   0.40915212606079876,\n",
       "   0.402565744491294,\n",
       "   0.384975610813126,\n",
       "   0.37790266880765555],\n",
       "  'running_test_loss': [0.9466236117482185,\n",
       "   0.6032470005750656,\n",
       "   0.5566984297335148,\n",
       "   0.5043909708410501,\n",
       "   0.4848955002427101,\n",
       "   0.4836096719652414,\n",
       "   0.4726233395934105,\n",
       "   0.42329415380954744,\n",
       "   0.3784632033854723,\n",
       "   0.3407866368442774,\n",
       "   0.28523733142763374,\n",
       "   0.27572194252163174,\n",
       "   0.2650539658591151,\n",
       "   0.23750913251191377,\n",
       "   0.2552927182614803]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2730233108997344,\n",
       "   0.8332919592410326,\n",
       "   0.6025100242905319,\n",
       "   0.5690312501229345,\n",
       "   0.5402633502706885,\n",
       "   0.5118831748329103,\n",
       "   0.48874190656468275,\n",
       "   0.47912840893492104,\n",
       "   0.45821939148940144,\n",
       "   0.4527417623624206,\n",
       "   0.435331602152437,\n",
       "   0.42852471123449504,\n",
       "   0.40709083538502455,\n",
       "   0.4087679623905569,\n",
       "   0.4144890554714948],\n",
       "  'running_test_loss': [1.0439525952935218,\n",
       "   0.5891434751451016,\n",
       "   0.46935357913374903,\n",
       "   0.451995709836483,\n",
       "   0.4276521895825863,\n",
       "   0.4086865717917681,\n",
       "   0.3732882516086102,\n",
       "   0.3223851424828172,\n",
       "   0.32342252604663374,\n",
       "   0.3312457410991192,\n",
       "   0.32031170550733806,\n",
       "   0.2900054273381829,\n",
       "   0.29231267124414445,\n",
       "   0.28412283957004547,\n",
       "   0.27349639162421224]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.1899454708397388,\n",
       "   0.7823869374394417,\n",
       "   0.6189845245331526,\n",
       "   0.5859273114055396,\n",
       "   0.5825016446039081,\n",
       "   0.5656751213595271,\n",
       "   0.5444908224605024,\n",
       "   0.5333944693394005,\n",
       "   0.511273628231138,\n",
       "   0.4892297209613025,\n",
       "   0.46280291470699014,\n",
       "   0.453132283333689,\n",
       "   0.4395176070276648,\n",
       "   0.4209422924835235,\n",
       "   0.4190284296963364],\n",
       "  'running_test_loss': [0.9582232424616813,\n",
       "   0.5978820922970772,\n",
       "   0.5161864849179983,\n",
       "   0.5002121629565954,\n",
       "   0.4714050076156855,\n",
       "   0.4579563802480698,\n",
       "   0.4268143000453711,\n",
       "   0.42009756617248056,\n",
       "   0.4012709985673428,\n",
       "   0.3544810899347067,\n",
       "   0.34136909145861866,\n",
       "   0.33408941760659217,\n",
       "   0.3107921760901809,\n",
       "   0.2984199145436287,\n",
       "   0.28396002169698475]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6264237412251532,\n",
       "   0.40958076482638717,\n",
       "   0.3936037612706423,\n",
       "   0.38258475756272675,\n",
       "   0.3767698443681002,\n",
       "   0.37468948937021196,\n",
       "   0.38616954130120573,\n",
       "   0.38580544385127724,\n",
       "   0.3637007192801684,\n",
       "   0.38048669575713573,\n",
       "   0.3744503066316247,\n",
       "   0.3619833373930305,\n",
       "   0.3662803198583424,\n",
       "   0.38730389370582996,\n",
       "   0.37600016850046813],\n",
       "  'running_test_loss': [0.3532365756854415,\n",
       "   0.25847594570368526,\n",
       "   0.2147671079263091,\n",
       "   0.24886902429163457,\n",
       "   0.2107733628898859,\n",
       "   0.20514299530535937,\n",
       "   0.2309633086435497,\n",
       "   0.23486358642578126,\n",
       "   0.23557487091049553,\n",
       "   0.23681707140058278,\n",
       "   0.2622893047332764,\n",
       "   0.26194870080798865,\n",
       "   0.22252040768042206,\n",
       "   0.2653006779588759,\n",
       "   0.22939924743026496]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.636062598656863,\n",
       "   0.4538583627529442,\n",
       "   0.4139396358653903,\n",
       "   0.39325815415009857,\n",
       "   0.3937319599185139,\n",
       "   0.4008110557030886,\n",
       "   0.3849973783455789,\n",
       "   0.395958349108696,\n",
       "   0.3913784274179488,\n",
       "   0.3893025546800345,\n",
       "   0.37574598538689313,\n",
       "   0.3910973549634218,\n",
       "   0.38023445402272044,\n",
       "   0.3924079070147127,\n",
       "   0.3787219474557787],\n",
       "  'running_test_loss': [0.36997987642884256,\n",
       "   0.29950925946235657,\n",
       "   0.2636613631248474,\n",
       "   0.2613075438514352,\n",
       "   0.2624564143642783,\n",
       "   0.2355147447064519,\n",
       "   0.24509730506688357,\n",
       "   0.22611760253086685,\n",
       "   0.20961695581674575,\n",
       "   0.23839651728048922,\n",
       "   0.23519584406167268,\n",
       "   0.21975744690746069,\n",
       "   0.23322016544640065,\n",
       "   0.2161541898921132,\n",
       "   0.24993910934776067]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.606964458078146,\n",
       "   0.39205135179683565,\n",
       "   0.39309913968667387,\n",
       "   0.3782554912846535,\n",
       "   0.37877042129635813,\n",
       "   0.3779110176116228,\n",
       "   0.380636008484289,\n",
       "   0.37734272019937637,\n",
       "   0.3785850659571588,\n",
       "   0.36757952901534735,\n",
       "   0.38100669035688045,\n",
       "   0.3849827038869262,\n",
       "   0.37091151752509177,\n",
       "   0.3774980919063091,\n",
       "   0.3860235921945423],\n",
       "  'running_test_loss': [0.29029029920697214,\n",
       "   0.22202618043869735,\n",
       "   0.25054112933576106,\n",
       "   0.250373582392931,\n",
       "   0.2268273091316223,\n",
       "   0.24757109977304936,\n",
       "   0.22057073710486294,\n",
       "   0.20999581489712,\n",
       "   0.23604211276397108,\n",
       "   0.2284279072470963,\n",
       "   0.23150812663137912,\n",
       "   0.2261474945396185,\n",
       "   0.22433064948767423,\n",
       "   0.22828687589615584,\n",
       "   0.23648747006431223]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6395880320481956,\n",
       "   0.3953225909266621,\n",
       "   0.38785262882709504,\n",
       "   0.3763913485966623,\n",
       "   0.3899423658568412,\n",
       "   0.3721434077527374,\n",
       "   0.3595071026496589,\n",
       "   0.3773546828981489,\n",
       "   0.3851834801584482,\n",
       "   0.3734514412470162,\n",
       "   0.3796950932964683,\n",
       "   0.3724206802342087,\n",
       "   0.38039295327849687,\n",
       "   0.3865676750615239,\n",
       "   0.37529404057189825],\n",
       "  'running_test_loss': [0.2779127959907055,\n",
       "   0.25687196921557187,\n",
       "   0.21950277004390956,\n",
       "   0.2277237962000072,\n",
       "   0.26132467180490493,\n",
       "   0.229585576467216,\n",
       "   0.23709811981767415,\n",
       "   0.24758107034489513,\n",
       "   0.22682263843715192,\n",
       "   0.2658896894194186,\n",
       "   0.2138370448537171,\n",
       "   0.2087574077770114,\n",
       "   0.24408282790333033,\n",
       "   0.2431639692373574,\n",
       "   0.22384463287889958]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.3828361219167709,\n",
       "   0.7829021267965436,\n",
       "   0.6134872231259942,\n",
       "   0.5917787980288267,\n",
       "   0.5859487508982419,\n",
       "   0.5814654364436865,\n",
       "   0.5729220809601248,\n",
       "   0.5627985201217234,\n",
       "   0.5583556085824967,\n",
       "   0.5369090516678989,\n",
       "   0.5349467005021871,\n",
       "   0.5062775066122412,\n",
       "   0.49098359774798156,\n",
       "   0.4848575210943818,\n",
       "   0.4702014032565057],\n",
       "  'running_test_loss': [1.060718883574009,\n",
       "   0.5771633526682853,\n",
       "   0.5080128555744886,\n",
       "   0.49652503997087477,\n",
       "   0.49023489609360693,\n",
       "   0.4722356439381838,\n",
       "   0.4627878589183092,\n",
       "   0.4510010055452585,\n",
       "   0.44341754212975504,\n",
       "   0.43231698632240295,\n",
       "   0.39375096462666986,\n",
       "   0.3761329737305641,\n",
       "   0.37201243050396443,\n",
       "   0.33958279211074116,\n",
       "   0.32162969999015334]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.286443150192499,\n",
       "   1.003277698904276,\n",
       "   0.7179602998867631,\n",
       "   0.5788890934363008,\n",
       "   0.5244032617099583,\n",
       "   0.48935666438192127,\n",
       "   0.4509870602935553,\n",
       "   0.4504505832120776,\n",
       "   0.42761214714497325,\n",
       "   0.41667018035426734,\n",
       "   0.4000255315098912,\n",
       "   0.40402272062376143,\n",
       "   0.3979601334501058,\n",
       "   0.39044645843096076,\n",
       "   0.39414859396405516],\n",
       "  'running_test_loss': [1.1213134276866912,\n",
       "   0.783018097281456,\n",
       "   0.520859920233488,\n",
       "   0.430752532184124,\n",
       "   0.393863605633378,\n",
       "   0.3342392420768738,\n",
       "   0.32514130011200904,\n",
       "   0.31573883790522816,\n",
       "   0.29616888459771873,\n",
       "   0.27220491647720335,\n",
       "   0.27097068160772325,\n",
       "   0.2691740594431758,\n",
       "   0.24284842405468227,\n",
       "   0.22534017160534858,\n",
       "   0.22299790639430284]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.0433746136724948,\n",
       "   0.707041694521904,\n",
       "   0.5944174511171877,\n",
       "   0.5699912639893592,\n",
       "   0.5427695751935243,\n",
       "   0.5145441209711135,\n",
       "   0.4779440304264426,\n",
       "   0.45864991741254924,\n",
       "   0.4323337790928781,\n",
       "   0.41239947712980213,\n",
       "   0.39955711061134935,\n",
       "   0.3965610413532704,\n",
       "   0.39260943384841085,\n",
       "   0.3912997813243419,\n",
       "   0.39262066190131006],\n",
       "  'running_test_loss': [0.8058817479014396,\n",
       "   0.567422813475132,\n",
       "   0.4803547789156437,\n",
       "   0.4632510975748301,\n",
       "   0.4314940184354782,\n",
       "   0.3855966369062662,\n",
       "   0.3450141987204552,\n",
       "   0.327342738173902,\n",
       "   0.3138778110221028,\n",
       "   0.2745837300270796,\n",
       "   0.2889086980372667,\n",
       "   0.2463873837143183,\n",
       "   0.2426800015196204,\n",
       "   0.23543253153562546,\n",
       "   0.24951283058151602]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.3263692221045493,\n",
       "   1.0235864638537169,\n",
       "   0.6975361337140202,\n",
       "   0.5943403819575905,\n",
       "   0.5636679498665035,\n",
       "   0.5414296359568834,\n",
       "   0.5098151175677776,\n",
       "   0.472185779530555,\n",
       "   0.4582675134949386,\n",
       "   0.43573547663167117,\n",
       "   0.42043091750703754,\n",
       "   0.41171738798730073,\n",
       "   0.4008002302236855,\n",
       "   0.39887948786839844,\n",
       "   0.3910706649720669],\n",
       "  'running_test_loss': [1.1772834306955338,\n",
       "   0.7897699165344239,\n",
       "   0.528565554022789,\n",
       "   0.4867301380634308,\n",
       "   0.4463295552134514,\n",
       "   0.4099399491399527,\n",
       "   0.36418255910277364,\n",
       "   0.33954381611198187,\n",
       "   0.310904875472188,\n",
       "   0.2975747532770038,\n",
       "   0.29608309984207154,\n",
       "   0.27687587633728983,\n",
       "   0.26924300033599136,\n",
       "   0.2594291538745165,\n",
       "   0.25714105140417814]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6527425114810467,\n",
       "   0.42707309999503196,\n",
       "   0.41749949513934553,\n",
       "   0.41170005380176006,\n",
       "   0.40680622970685365,\n",
       "   0.41258770556189117,\n",
       "   0.41481194785796105,\n",
       "   0.4060220270138234,\n",
       "   0.4144079051073641,\n",
       "   0.40902827599085867,\n",
       "   0.4075144481193274,\n",
       "   0.40102029011584817,\n",
       "   0.41061378667131065,\n",
       "   0.4179245722200722,\n",
       "   0.40766855942085384],\n",
       "  'running_test_loss': [0.3035197205096483,\n",
       "   0.24700978480279445,\n",
       "   0.2458905543386936,\n",
       "   0.31122105933725835,\n",
       "   0.23914610642939807,\n",
       "   0.265838472917676,\n",
       "   0.24985128667205572,\n",
       "   0.24823092859238385,\n",
       "   0.24613653175532818,\n",
       "   0.2232644782587886,\n",
       "   0.26865243759006263,\n",
       "   0.25466874115169047,\n",
       "   0.24026749234646558,\n",
       "   0.2636182903125882,\n",
       "   0.23992312747985126]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6870636716671288,\n",
       "   0.4684685944393277,\n",
       "   0.42526146363466977,\n",
       "   0.4171538582537323,\n",
       "   0.42543718330562114,\n",
       "   0.4240604501031339,\n",
       "   0.4080826601292938,\n",
       "   0.41297495102509857,\n",
       "   0.4065832202415913,\n",
       "   0.4067316836491227,\n",
       "   0.4065764597989619,\n",
       "   0.412099898410961,\n",
       "   0.406492599369958,\n",
       "   0.40716618023812773,\n",
       "   0.41607887382619085],\n",
       "  'running_test_loss': [0.3832266663014889,\n",
       "   0.27265367621555925,\n",
       "   0.24791735604405404,\n",
       "   0.2691209723427892,\n",
       "   0.2582075015082955,\n",
       "   0.28220410279929636,\n",
       "   0.25541854355484245,\n",
       "   0.25606981620192526,\n",
       "   0.2989410353265703,\n",
       "   0.23950925374403595,\n",
       "   0.24239065775647758,\n",
       "   0.2387953510135412,\n",
       "   0.2725968599319458,\n",
       "   0.2742072730511427,\n",
       "   0.27060252740979196]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6864956222847104,\n",
       "   0.4804847574979067,\n",
       "   0.43597942067310214,\n",
       "   0.42981123181991276,\n",
       "   0.415975188203156,\n",
       "   0.41265317423269154,\n",
       "   0.4176746829878539,\n",
       "   0.4043594152200967,\n",
       "   0.4197188998479396,\n",
       "   0.42199656725861134,\n",
       "   0.41150046803988516,\n",
       "   0.4046576611790806,\n",
       "   0.40877140998840333,\n",
       "   0.4139797533303499,\n",
       "   0.4106098022405058],\n",
       "  'running_test_loss': [0.4428571984916925,\n",
       "   0.3003775266557932,\n",
       "   0.24820787468925118,\n",
       "   0.2584391631186008,\n",
       "   0.2749524158239365,\n",
       "   0.24318058693781494,\n",
       "   0.24897285729646682,\n",
       "   0.30420485947281123,\n",
       "   0.25508681865409016,\n",
       "   0.24827180873602628,\n",
       "   0.25457950539886953,\n",
       "   0.23255815543234348,\n",
       "   0.24772034332156181,\n",
       "   0.265336028970778,\n",
       "   0.2844745960459113]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6363590625114739,\n",
       "   0.4508757619652897,\n",
       "   0.42484779494814573,\n",
       "   0.4076311982795596,\n",
       "   0.4209615885838866,\n",
       "   0.4147641876619309,\n",
       "   0.41665047721005977,\n",
       "   0.41137572925537824,\n",
       "   0.40546786014921965,\n",
       "   0.4130046385899186,\n",
       "   0.40719499086029826,\n",
       "   0.4013504386972636,\n",
       "   0.40953937341459096,\n",
       "   0.4034458802640438,\n",
       "   0.419703117525205],\n",
       "  'running_test_loss': [0.3370017955079675,\n",
       "   0.25587219443172216,\n",
       "   0.2339150434732437,\n",
       "   0.26043466735631227,\n",
       "   0.25952029768377544,\n",
       "   0.2515240509808063,\n",
       "   0.22671492762863635,\n",
       "   0.26574281092733143,\n",
       "   0.24195484913885593,\n",
       "   0.24747657744213938,\n",
       "   0.24744555715471506,\n",
       "   0.260120813138783,\n",
       "   0.26690902654081583,\n",
       "   0.2728057449311018,\n",
       "   0.24175351575016976]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.309457353502512,\n",
       "   0.8495132082328201,\n",
       "   0.6396539066359401,\n",
       "   0.5931358033046127,\n",
       "   0.5610573447681964,\n",
       "   0.5358708623982966,\n",
       "   0.5235003510490059,\n",
       "   0.5066846137680113,\n",
       "   0.4912534476816654,\n",
       "   0.47077648889273405,\n",
       "   0.4775535992719233,\n",
       "   0.4605005877558142,\n",
       "   0.4582819431275129,\n",
       "   0.44397246627137066,\n",
       "   0.4450891520269215],\n",
       "  'running_test_loss': [1.090766569674015,\n",
       "   0.5892742602527141,\n",
       "   0.5015036160498858,\n",
       "   0.45828215323388577,\n",
       "   0.4210768024623394,\n",
       "   0.40007947094738483,\n",
       "   0.38859966792166234,\n",
       "   0.36265491124242544,\n",
       "   0.33548684131354095,\n",
       "   0.34320935789495705,\n",
       "   0.2997175720706582,\n",
       "   0.33903839744627473,\n",
       "   0.2813194540888071,\n",
       "   0.30412190295755864,\n",
       "   0.3103000846505165]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.1101824916154146,\n",
       "   0.7930245638266206,\n",
       "   0.6163969656452537,\n",
       "   0.580515803322196,\n",
       "   0.5692979078926146,\n",
       "   0.5457142646238208,\n",
       "   0.5037185987643897,\n",
       "   0.5005594342388213,\n",
       "   0.4779323507659137,\n",
       "   0.4593300972878933,\n",
       "   0.4563778074458241,\n",
       "   0.43303913144394757,\n",
       "   0.4272566650435328,\n",
       "   0.4245073636434972,\n",
       "   0.4091095590777695],\n",
       "  'running_test_loss': [0.9252762520313262,\n",
       "   0.5865579842031002,\n",
       "   0.485003005489707,\n",
       "   0.46620387375354766,\n",
       "   0.4367164847254753,\n",
       "   0.40709385737776754,\n",
       "   0.37394014485180377,\n",
       "   0.3554219266027212,\n",
       "   0.3313424003496766,\n",
       "   0.27233611546456815,\n",
       "   0.29299916222691536,\n",
       "   0.2860311842337251,\n",
       "   0.27127782110124826,\n",
       "   0.28597874954342845,\n",
       "   0.2831497272104025]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.1639149432629348,\n",
       "   0.7835021407902241,\n",
       "   0.5839109689556062,\n",
       "   0.5223040179722012,\n",
       "   0.492417600043118,\n",
       "   0.4755454042181373,\n",
       "   0.4701040954329073,\n",
       "   0.45378554575145247,\n",
       "   0.46495999390259385,\n",
       "   0.4422810257878155,\n",
       "   0.44901992662809787,\n",
       "   0.4291824338957667,\n",
       "   0.4429950940608978,\n",
       "   0.43258863236755135,\n",
       "   0.4326725106034428],\n",
       "  'running_test_loss': [0.9030607372522355,\n",
       "   0.5572171138226986,\n",
       "   0.4329942594468594,\n",
       "   0.39304505541920665,\n",
       "   0.35669428650289775,\n",
       "   0.33253700513392687,\n",
       "   0.3189900462701917,\n",
       "   0.3058156126365066,\n",
       "   0.3063031913340092,\n",
       "   0.3080461065471172,\n",
       "   0.30758364938199523,\n",
       "   0.26612154744565486,\n",
       "   0.28509916756302117,\n",
       "   0.2829891120642424,\n",
       "   0.27085662238299846]},\n",
       " {'bi_mamba_stacks': 1,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.107906493768096,\n",
       "   0.7882719764858485,\n",
       "   0.6324714174866677,\n",
       "   0.5974441892281175,\n",
       "   0.5567671823129058,\n",
       "   0.5289772379584611,\n",
       "   0.5167690007947385,\n",
       "   0.4969147854298353,\n",
       "   0.48015571845695376,\n",
       "   0.4611050557345152,\n",
       "   0.45974839946255086,\n",
       "   0.4553501366917044,\n",
       "   0.44746182691305875,\n",
       "   0.4468830713815987,\n",
       "   0.4457490098662674],\n",
       "  'running_test_loss': [0.9108389964699746,\n",
       "   0.6428201556205749,\n",
       "   0.5274776947498322,\n",
       "   0.48522561736404896,\n",
       "   0.46898600049316885,\n",
       "   0.4009091183543205,\n",
       "   0.416136633567512,\n",
       "   0.35496707666665317,\n",
       "   0.3261385993286967,\n",
       "   0.33528334062546494,\n",
       "   0.3125356242060661,\n",
       "   0.31934712793678044,\n",
       "   0.28643322877585886,\n",
       "   0.30224517833441494,\n",
       "   0.3093438061699271]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5666122589819134,\n",
       "   0.3650365181826055,\n",
       "   0.34316359522286805,\n",
       "   0.3461660856707022,\n",
       "   0.3523278827872127,\n",
       "   0.3504391803452745,\n",
       "   0.3407700711861253,\n",
       "   0.34974108851514757,\n",
       "   0.35078675890807065,\n",
       "   0.3511974731925875,\n",
       "   0.3271897410042584,\n",
       "   0.33794451740104703,\n",
       "   0.35187279250472786,\n",
       "   0.3428626253362745,\n",
       "   0.35831707578152416],\n",
       "  'running_test_loss': [0.2315570280700922,\n",
       "   0.2356492361985147,\n",
       "   0.265551505535841,\n",
       "   0.21805089661851526,\n",
       "   0.20606041891500354,\n",
       "   0.22259699247777462,\n",
       "   0.23484818326309323,\n",
       "   0.22396576419472694,\n",
       "   0.1886349161155522,\n",
       "   0.2450896325521171,\n",
       "   0.24095416417345406,\n",
       "   0.19935764733701944,\n",
       "   0.21509842090308667,\n",
       "   0.2250582006946206,\n",
       "   0.21600364781916143]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6344555926229805,\n",
       "   0.3746069539152086,\n",
       "   0.37355206105858085,\n",
       "   0.3473752361349762,\n",
       "   0.3537025763653219,\n",
       "   0.3531928758323193,\n",
       "   0.35833289448171857,\n",
       "   0.35986240982078016,\n",
       "   0.3554302466381341,\n",
       "   0.33386722408700736,\n",
       "   0.34123495055362585,\n",
       "   0.34900749757885935,\n",
       "   0.33078085280023517,\n",
       "   0.32157964318059384,\n",
       "   0.32041764196008443],\n",
       "  'running_test_loss': [0.2340947624668479,\n",
       "   0.26231935046613214,\n",
       "   0.2714292181842029,\n",
       "   0.20700707476586103,\n",
       "   0.2254058344103396,\n",
       "   0.26532585591077806,\n",
       "   0.21579967863857746,\n",
       "   0.24653766121715306,\n",
       "   0.22180066857486963,\n",
       "   0.21438633622601627,\n",
       "   0.20105760738253595,\n",
       "   0.2765288561582565,\n",
       "   0.1701743034645915,\n",
       "   0.17920631989836694,\n",
       "   0.16481908416375518]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5713730471022427,\n",
       "   0.37044756099581716,\n",
       "   0.3670789989363402,\n",
       "   0.3505958764720708,\n",
       "   0.36871737415902317,\n",
       "   0.35314312268514186,\n",
       "   0.3482638074690476,\n",
       "   0.3422067641094327,\n",
       "   0.35629227399360386,\n",
       "   0.33283917696215215,\n",
       "   0.3458589507918805,\n",
       "   0.3486036800220609,\n",
       "   0.3537364599807188,\n",
       "   0.3494795961212367,\n",
       "   0.3598461469355971],\n",
       "  'running_test_loss': [0.3039057896286249,\n",
       "   0.2331459004059434,\n",
       "   0.21751564890146255,\n",
       "   0.24441833490505815,\n",
       "   0.2559453133866191,\n",
       "   0.24408521970734,\n",
       "   0.2263129258528352,\n",
       "   0.22908372955396772,\n",
       "   0.2204574646614492,\n",
       "   0.22257513100281356,\n",
       "   0.23243866972625254,\n",
       "   0.21061068821698428,\n",
       "   0.2135333226621151,\n",
       "   0.229223104827106,\n",
       "   0.19739315601065754]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6579080475121737,\n",
       "   0.44464953562244774,\n",
       "   0.39400316297076643,\n",
       "   0.35154096404090523,\n",
       "   0.3746725282352418,\n",
       "   0.36103211630135773,\n",
       "   0.3532780333282426,\n",
       "   0.3543144984357059,\n",
       "   0.34958637279458343,\n",
       "   0.36174058507196605,\n",
       "   0.3507540506031364,\n",
       "   0.3324916029907763,\n",
       "   0.3563288782723248,\n",
       "   0.36146703283302484,\n",
       "   0.349079546360299],\n",
       "  'running_test_loss': [0.37527035146951676,\n",
       "   0.2683226881921291,\n",
       "   0.23719558775424956,\n",
       "   0.21237337533384562,\n",
       "   0.24742492526769638,\n",
       "   0.2193689549341798,\n",
       "   0.25060397665947676,\n",
       "   0.25672085462138056,\n",
       "   0.2292291039787233,\n",
       "   0.2580716563388705,\n",
       "   0.1937958069704473,\n",
       "   0.22132798798382283,\n",
       "   0.24883672244846822,\n",
       "   0.2076354343444109,\n",
       "   0.2551253941841424]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.3685114827752114,\n",
       "   0.9489553718268872,\n",
       "   0.6244010106474162,\n",
       "   0.559292064756155,\n",
       "   0.5169764107465744,\n",
       "   0.4889206639677286,\n",
       "   0.44833324240520595,\n",
       "   0.40632822273299096,\n",
       "   0.38047054240480066,\n",
       "   0.35967217695899306,\n",
       "   0.3645825045835227,\n",
       "   0.36932428465224804,\n",
       "   0.36714124572463336,\n",
       "   0.36654122918844223,\n",
       "   0.36252014118246734],\n",
       "  'running_test_loss': [1.1816930800676346,\n",
       "   0.6629743847250938,\n",
       "   0.47262030936777594,\n",
       "   0.418928794413805,\n",
       "   0.3944590437412262,\n",
       "   0.32899769090116027,\n",
       "   0.2925670348852873,\n",
       "   0.24797698210924865,\n",
       "   0.22291258469223976,\n",
       "   0.24019781641662122,\n",
       "   0.21079058296978473,\n",
       "   0.2332604468613863,\n",
       "   0.20999890368431806,\n",
       "   0.22624993707984686,\n",
       "   0.25173598181456325]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2642406640946866,\n",
       "   1.03321331910789,\n",
       "   0.7416581184789538,\n",
       "   0.5811659919843077,\n",
       "   0.519166401270777,\n",
       "   0.48858843974769117,\n",
       "   0.4437472866475582,\n",
       "   0.42286754998378456,\n",
       "   0.4120772582665086,\n",
       "   0.4016975666861981,\n",
       "   0.3968809016048908,\n",
       "   0.37974920017644764,\n",
       "   0.3608472965005785,\n",
       "   0.36581616930663585,\n",
       "   0.359338610926643],\n",
       "  'running_test_loss': [1.151087287068367,\n",
       "   0.8621530976891517,\n",
       "   0.5940400901436805,\n",
       "   0.43042730338871477,\n",
       "   0.38304004706442357,\n",
       "   0.40296986788511274,\n",
       "   0.3355221461132169,\n",
       "   0.2874420776963234,\n",
       "   0.28489411640912293,\n",
       "   0.29631453562527893,\n",
       "   0.26671929970383645,\n",
       "   0.2530861316248775,\n",
       "   0.23725461773574352,\n",
       "   0.2475510735809803,\n",
       "   0.2834711256995797]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.1690716081857682,\n",
       "   0.7966846833005548,\n",
       "   0.6008713503554464,\n",
       "   0.5290284127369523,\n",
       "   0.49961989544332025,\n",
       "   0.466667387932539,\n",
       "   0.43890407343395055,\n",
       "   0.42953196580521763,\n",
       "   0.4137800524570048,\n",
       "   0.38631695820018647,\n",
       "   0.3999832689203322,\n",
       "   0.38063116614706816,\n",
       "   0.36255723390728234,\n",
       "   0.38189351656474174,\n",
       "   0.371244640853256],\n",
       "  'running_test_loss': [0.9561764672398567,\n",
       "   0.6009270279109478,\n",
       "   0.4576829466223717,\n",
       "   0.3772483339160681,\n",
       "   0.3735247924178839,\n",
       "   0.3330702290311456,\n",
       "   0.3349964888393879,\n",
       "   0.32743926454335454,\n",
       "   0.26893656119704246,\n",
       "   0.2741580544412136,\n",
       "   0.26602750420570376,\n",
       "   0.2742080047726631,\n",
       "   0.26583403514698145,\n",
       "   0.2699121979624033,\n",
       "   0.23697591830044984]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.4693577174842358,\n",
       "   0.9291785087436437,\n",
       "   0.6289131918177009,\n",
       "   0.5682294852845371,\n",
       "   0.5117129110172391,\n",
       "   0.45804813589900734,\n",
       "   0.42549307878129183,\n",
       "   0.4007576535269618,\n",
       "   0.39326604375615715,\n",
       "   0.3656111936271191,\n",
       "   0.37984087415970863,\n",
       "   0.3662177628092468,\n",
       "   0.35801360561512413,\n",
       "   0.36368508319370446,\n",
       "   0.3521848336793482],\n",
       "  'running_test_loss': [1.241758908033371,\n",
       "   0.6083482836186885,\n",
       "   0.48059324190020564,\n",
       "   0.4265543430298567,\n",
       "   0.3719215792417526,\n",
       "   0.34513493835926057,\n",
       "   0.28722480334341527,\n",
       "   0.252961210347712,\n",
       "   0.2572005285322666,\n",
       "   0.269826985783875,\n",
       "   0.2344821260496974,\n",
       "   0.24546016797423362,\n",
       "   0.23409672699868678,\n",
       "   0.20570148359984158,\n",
       "   0.23800873579457402]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6068348189629614,\n",
       "   0.38647918064147235,\n",
       "   0.38625979332253335,\n",
       "   0.3808000409975648,\n",
       "   0.3728975081816316,\n",
       "   0.3681468701735139,\n",
       "   0.3742942397575825,\n",
       "   0.3688328377623111,\n",
       "   0.3659457194432616,\n",
       "   0.3730998422857374,\n",
       "   0.3696043382957578,\n",
       "   0.3750455725658685,\n",
       "   0.3623194447811693,\n",
       "   0.3554992149304599,\n",
       "   0.3678263324778527],\n",
       "  'running_test_loss': [0.25857853550463916,\n",
       "   0.27770263671875,\n",
       "   0.22458237402141093,\n",
       "   0.213753504678607,\n",
       "   0.2455368474498391,\n",
       "   0.23737964749336243,\n",
       "   0.20582604724913836,\n",
       "   0.24890458766371013,\n",
       "   0.2288496620208025,\n",
       "   0.24944928396493196,\n",
       "   0.21620042100548745,\n",
       "   0.20373258877545594,\n",
       "   0.239808383397758,\n",
       "   0.2255833829380572,\n",
       "   0.20105538453906774]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6294927742891013,\n",
       "   0.3723391960002482,\n",
       "   0.370531143900007,\n",
       "   0.3695364946126938,\n",
       "   0.36057068799622355,\n",
       "   0.3760900436900556,\n",
       "   0.3601115807425231,\n",
       "   0.36668306472711265,\n",
       "   0.35532391162589194,\n",
       "   0.3567773458827287,\n",
       "   0.35010511898435653,\n",
       "   0.33239574492909013,\n",
       "   0.3438601313624531,\n",
       "   0.3441174187231809,\n",
       "   0.3310527955368161],\n",
       "  'running_test_loss': [0.21748824164271355,\n",
       "   0.239974161144346,\n",
       "   0.23415231110528112,\n",
       "   0.2301354341208935,\n",
       "   0.23648215360939503,\n",
       "   0.21679965756833552,\n",
       "   0.19686928544193505,\n",
       "   0.2192614789493382,\n",
       "   0.24220389317721128,\n",
       "   0.24263910233974456,\n",
       "   0.24370846275240182,\n",
       "   0.2276689907349646,\n",
       "   0.18486479548737406,\n",
       "   0.20478867372497916,\n",
       "   0.1748546246998012]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6947071790881455,\n",
       "   0.396416301894933,\n",
       "   0.3807238272111863,\n",
       "   0.3701320408470929,\n",
       "   0.36736747494898736,\n",
       "   0.36198443588800727,\n",
       "   0.353431150354445,\n",
       "   0.35841932203620674,\n",
       "   0.3603946802671999,\n",
       "   0.34976958204992115,\n",
       "   0.3363297989964485,\n",
       "   0.33112838320434096,\n",
       "   0.3396269291918725,\n",
       "   0.32522260066121816,\n",
       "   0.3254469812661409],\n",
       "  'running_test_loss': [0.2543258722499013,\n",
       "   0.25607630584388974,\n",
       "   0.24762401774525641,\n",
       "   0.22860055368393659,\n",
       "   0.22169561203569174,\n",
       "   0.2246702708862722,\n",
       "   0.20492554334923624,\n",
       "   0.22222517382353543,\n",
       "   0.21734116109088064,\n",
       "   0.2198321448639035,\n",
       "   0.21594233881682157,\n",
       "   0.22226046439260244,\n",
       "   0.18838592398911713,\n",
       "   0.20791001019999386,\n",
       "   0.2016050363332033]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5544099816773087,\n",
       "   0.4009003369975835,\n",
       "   0.3710075882542878,\n",
       "   0.38448787429369985,\n",
       "   0.3565167223289609,\n",
       "   0.36060430347919464,\n",
       "   0.35666821235790847,\n",
       "   0.3551823975890875,\n",
       "   0.35217807653360067,\n",
       "   0.3542949727084488,\n",
       "   0.3402957752160728,\n",
       "   0.3562255975231528,\n",
       "   0.34116464669816193,\n",
       "   0.3250492188986391,\n",
       "   0.3481716794520617],\n",
       "  'running_test_loss': [0.21054002773016692,\n",
       "   0.2552697241306305,\n",
       "   0.2451482757553458,\n",
       "   0.22231760628521444,\n",
       "   0.20804218443110586,\n",
       "   0.18863317120820283,\n",
       "   0.21829435132443906,\n",
       "   0.20888810565695168,\n",
       "   0.19774042624980212,\n",
       "   0.21688187787309288,\n",
       "   0.18960689099505543,\n",
       "   0.2048934373818338,\n",
       "   0.20954233210533857,\n",
       "   0.18280525775626302,\n",
       "   0.19274202985689043]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.1230096036195756,\n",
       "   0.8130546003207564,\n",
       "   0.6561647391319275,\n",
       "   0.5910239839181304,\n",
       "   0.5477477194555104,\n",
       "   0.5239271896518767,\n",
       "   0.4631740984134376,\n",
       "   0.4386048209480941,\n",
       "   0.41531761730089783,\n",
       "   0.40612939243204893,\n",
       "   0.41805083816871047,\n",
       "   0.410679802717641,\n",
       "   0.3845963652152568,\n",
       "   0.3904587821103632,\n",
       "   0.38825148800387976],\n",
       "  'running_test_loss': [0.9143106701970101,\n",
       "   0.6110756132006645,\n",
       "   0.5075647167861461,\n",
       "   0.4527556648105383,\n",
       "   0.39869765013456343,\n",
       "   0.36617422476410866,\n",
       "   0.3215388834103942,\n",
       "   0.28791056867688897,\n",
       "   0.2359024579077959,\n",
       "   0.243229644484818,\n",
       "   0.24569738879799843,\n",
       "   0.23538515467196702,\n",
       "   0.26311531890183687,\n",
       "   0.23136852022260426,\n",
       "   0.2631984797865152]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2876545049250125,\n",
       "   0.9938936089724302,\n",
       "   0.7011068980395794,\n",
       "   0.5676374668069184,\n",
       "   0.49888874888420104,\n",
       "   0.4387883924692869,\n",
       "   0.4106041303370148,\n",
       "   0.39788242949172853,\n",
       "   0.3920782168954611,\n",
       "   0.39578968587331476,\n",
       "   0.3994317723438144,\n",
       "   0.3908196075540036,\n",
       "   0.3856132737826556,\n",
       "   0.38207148667424917,\n",
       "   0.4000346521381289],\n",
       "  'running_test_loss': [1.1499302989244462,\n",
       "   0.7887633666396141,\n",
       "   0.5448394247889519,\n",
       "   0.40604070521891117,\n",
       "   0.3372177931666374,\n",
       "   0.2926241208985448,\n",
       "   0.24223324179649353,\n",
       "   0.25690287046134475,\n",
       "   0.25159321311861277,\n",
       "   0.22196410376578568,\n",
       "   0.2694714516401291,\n",
       "   0.2452419450879097,\n",
       "   0.2564431644976139,\n",
       "   0.23056016128510237,\n",
       "   0.24516884967684746]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.386733301281929,\n",
       "   0.9806663160771132,\n",
       "   0.6350995342060923,\n",
       "   0.5990820990875363,\n",
       "   0.5859674466215075,\n",
       "   0.5652369261533022,\n",
       "   0.5425953370518982,\n",
       "   0.5146954998001456,\n",
       "   0.46418568965047596,\n",
       "   0.44917080651968716,\n",
       "   0.4291132423095405,\n",
       "   0.421181823797524,\n",
       "   0.4077618722151965,\n",
       "   0.4063502555154264,\n",
       "   0.39899664183147254],\n",
       "  'running_test_loss': [1.2172705799341201,\n",
       "   0.6501660551130771,\n",
       "   0.49619825661182404,\n",
       "   0.4685135295242071,\n",
       "   0.4542913480848074,\n",
       "   0.44049689069390296,\n",
       "   0.38081233374774454,\n",
       "   0.3511724426597357,\n",
       "   0.3266611421853304,\n",
       "   0.30491141438484193,\n",
       "   0.2625207021459937,\n",
       "   0.26699425403028726,\n",
       "   0.24703302323818208,\n",
       "   0.2747898800671101,\n",
       "   0.2352792750671506]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.085364215001464,\n",
       "   0.7328629953041673,\n",
       "   0.6185195446759463,\n",
       "   0.6026589222252369,\n",
       "   0.5690781939215959,\n",
       "   0.530776868276298,\n",
       "   0.4782772875763476,\n",
       "   0.4424226852040738,\n",
       "   0.41388717157766225,\n",
       "   0.3933529157284647,\n",
       "   0.3843376845587045,\n",
       "   0.36042078386992216,\n",
       "   0.3696697182673961,\n",
       "   0.3746736955083907,\n",
       "   0.3829611164052039],\n",
       "  'running_test_loss': [0.8060604339838028,\n",
       "   0.5431604723632336,\n",
       "   0.49761673256754874,\n",
       "   0.4638295320421457,\n",
       "   0.4394103107601404,\n",
       "   0.39552290469408036,\n",
       "   0.31227853525429966,\n",
       "   0.2580648967251182,\n",
       "   0.26350022345781327,\n",
       "   0.24695698134601116,\n",
       "   0.2246207293868065,\n",
       "   0.25500500231981277,\n",
       "   0.2038592689111829,\n",
       "   0.2514632149413228,\n",
       "   0.2519298563525081]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6143506520427764,\n",
       "   0.4005639456212521,\n",
       "   0.39975151075050236,\n",
       "   0.3888914258684963,\n",
       "   0.3760255869850516,\n",
       "   0.3744475225545466,\n",
       "   0.36791716365143656,\n",
       "   0.3646187952905893,\n",
       "   0.3653613635990769,\n",
       "   0.3494958930462599,\n",
       "   0.36420171849429606,\n",
       "   0.3525082730688155,\n",
       "   0.35700058268383145,\n",
       "   0.34048081999644636,\n",
       "   0.3572726612631232],\n",
       "  'running_test_loss': [0.25980353336781264,\n",
       "   0.25373679772019386,\n",
       "   0.2685325387120247,\n",
       "   0.20756951838731766,\n",
       "   0.24267731949687005,\n",
       "   0.20529134068638086,\n",
       "   0.18092680245637893,\n",
       "   0.24291525626555086,\n",
       "   0.20927537575364114,\n",
       "   0.22031287537887692,\n",
       "   0.2053749628737569,\n",
       "   0.2398961454257369,\n",
       "   0.2508842422068119,\n",
       "   0.19888694947585464,\n",
       "   0.21319765832275153]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6332386148348451,\n",
       "   0.4088580725062638,\n",
       "   0.4010406276024878,\n",
       "   0.37800335679203273,\n",
       "   0.37970479977317156,\n",
       "   0.3885694872587919,\n",
       "   0.35949853299185636,\n",
       "   0.36927485758438705,\n",
       "   0.36905190678313377,\n",
       "   0.36692570050247014,\n",
       "   0.35126923777163027,\n",
       "   0.3545100332610309,\n",
       "   0.3530141952820122,\n",
       "   0.36466098492033777,\n",
       "   0.35472157002426685],\n",
       "  'running_test_loss': [0.2994591373950243,\n",
       "   0.2133283719047904,\n",
       "   0.21465971674770118,\n",
       "   0.22527017446234823,\n",
       "   0.2800656388886273,\n",
       "   0.23951747428625822,\n",
       "   0.2441442441008985,\n",
       "   0.23816899389028548,\n",
       "   0.20644306078553198,\n",
       "   0.22971252417191862,\n",
       "   0.2369960492104292,\n",
       "   0.20643354538828135,\n",
       "   0.22080769944936038,\n",
       "   0.2199354595504701,\n",
       "   0.2041737337037921]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.609490689272061,\n",
       "   0.4171588462498039,\n",
       "   0.3947880637831986,\n",
       "   0.3866003038920462,\n",
       "   0.38828407507389784,\n",
       "   0.37859935415908696,\n",
       "   0.39751843621023,\n",
       "   0.37189827622845767,\n",
       "   0.3567998141609132,\n",
       "   0.3577365991473198,\n",
       "   0.3627235603146255,\n",
       "   0.3504646308906376,\n",
       "   0.35710350862704215,\n",
       "   0.3473901528213173,\n",
       "   0.34626427036710083],\n",
       "  'running_test_loss': [0.27970015272498133,\n",
       "   0.25191018734127285,\n",
       "   0.22813847336918117,\n",
       "   0.2126996741630137,\n",
       "   0.22220918036997317,\n",
       "   0.2525287595577538,\n",
       "   0.24630068119615317,\n",
       "   0.2032892606407404,\n",
       "   0.2131771537847817,\n",
       "   0.21238203387707472,\n",
       "   0.24714232712984086,\n",
       "   0.21029570074751974,\n",
       "   0.19286545233801008,\n",
       "   0.18837612930685282,\n",
       "   0.19701297983527183]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6963274519331754,\n",
       "   0.4156726158224046,\n",
       "   0.38239771088585256,\n",
       "   0.3695638946257532,\n",
       "   0.3682123871985823,\n",
       "   0.34578733370639386,\n",
       "   0.35715232000686226,\n",
       "   0.34271073557436466,\n",
       "   0.34479749521240594,\n",
       "   0.3447109448071569,\n",
       "   0.3619760967884213,\n",
       "   0.3425582531001419,\n",
       "   0.3336449252255261,\n",
       "   0.347861502924934,\n",
       "   0.3489960394706577],\n",
       "  'running_test_loss': [0.2760600154101849,\n",
       "   0.2166824469342828,\n",
       "   0.2277025730535388,\n",
       "   0.20618894204497337,\n",
       "   0.22780717737972736,\n",
       "   0.21773463007062674,\n",
       "   0.2129275302402675,\n",
       "   0.19646933883428574,\n",
       "   0.2173286691494286,\n",
       "   0.19427068009972573,\n",
       "   0.20855134833604097,\n",
       "   0.20501178486272692,\n",
       "   0.2035871922597289,\n",
       "   0.19436112605035305,\n",
       "   0.19288899058476092]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [0.9916036576032639,\n",
       "   0.7515880143269896,\n",
       "   0.6152350388094783,\n",
       "   0.565283079072833,\n",
       "   0.5104008500277996,\n",
       "   0.4579486353136599,\n",
       "   0.42681894518435004,\n",
       "   0.3968568390514702,\n",
       "   0.4084153248835355,\n",
       "   0.39808516805060207,\n",
       "   0.405128256091848,\n",
       "   0.40960611999966207,\n",
       "   0.3967907663714141,\n",
       "   0.391231426410377,\n",
       "   0.3877053670212626],\n",
       "  'running_test_loss': [0.8203425288200379,\n",
       "   0.5938497714698314,\n",
       "   0.48325797021389005,\n",
       "   0.4234599743038416,\n",
       "   0.33873098753392694,\n",
       "   0.30232242692261935,\n",
       "   0.2898813509196043,\n",
       "   0.2525775690749288,\n",
       "   0.2616372882947326,\n",
       "   0.23021525904536247,\n",
       "   0.24896199759095908,\n",
       "   0.23012742191553115,\n",
       "   0.2554960997030139,\n",
       "   0.21356652181595565,\n",
       "   0.2355226968973875]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2197794757783413,\n",
       "   0.8076245326548814,\n",
       "   0.6156160680577158,\n",
       "   0.5545521740801632,\n",
       "   0.5049088023416698,\n",
       "   0.4721946460567415,\n",
       "   0.43569752091541886,\n",
       "   0.42095650524832307,\n",
       "   0.4209811604209244,\n",
       "   0.41543347515165807,\n",
       "   0.4044978235848248,\n",
       "   0.4122351869009435,\n",
       "   0.41200592724606394,\n",
       "   0.4058409542310983,\n",
       "   0.3975817933585495],\n",
       "  'running_test_loss': [0.9631861093640327,\n",
       "   0.5373296789824963,\n",
       "   0.4269280193001032,\n",
       "   0.40311475105583666,\n",
       "   0.3073695924505591,\n",
       "   0.28642242066562174,\n",
       "   0.2540412295237184,\n",
       "   0.2455486799404025,\n",
       "   0.2684662000834942,\n",
       "   0.27282291527837516,\n",
       "   0.23380357947200536,\n",
       "   0.242702030017972,\n",
       "   0.2375396054238081,\n",
       "   0.24017427138984204,\n",
       "   0.26176633588969705]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.411295011639595,\n",
       "   1.0051130896806717,\n",
       "   0.675185873657465,\n",
       "   0.5986650566756725,\n",
       "   0.5719325193203986,\n",
       "   0.5342724240943789,\n",
       "   0.5023923130705953,\n",
       "   0.46858187843114135,\n",
       "   0.44742439213208857,\n",
       "   0.4377035406138748,\n",
       "   0.4141842052154243,\n",
       "   0.41158654882572593,\n",
       "   0.38900182153098284,\n",
       "   0.3984215909149498,\n",
       "   0.40244297809898855],\n",
       "  'running_test_loss': [1.2125900834798813,\n",
       "   0.7192856577038765,\n",
       "   0.5109459421038628,\n",
       "   0.44740673862397673,\n",
       "   0.43721539378166197,\n",
       "   0.3735281760245562,\n",
       "   0.34609737612307073,\n",
       "   0.2998417592793703,\n",
       "   0.2972697651013732,\n",
       "   0.2619307206571102,\n",
       "   0.2795711667463183,\n",
       "   0.2641725977137685,\n",
       "   0.2331519015878439,\n",
       "   0.234283010289073,\n",
       "   0.27492372162640094]},\n",
       " {'bi_mamba_stacks': 2,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2645553117990493,\n",
       "   0.8606729302182794,\n",
       "   0.6631206630542874,\n",
       "   0.6295218480005861,\n",
       "   0.6149879157170653,\n",
       "   0.5958981311880052,\n",
       "   0.5827302680909634,\n",
       "   0.5657082027196885,\n",
       "   0.5528743344917894,\n",
       "   0.5218543929234147,\n",
       "   0.47915480080991985,\n",
       "   0.4369528446346521,\n",
       "   0.41739066429436206,\n",
       "   0.40532954638823865,\n",
       "   0.4134136137459427],\n",
       "  'running_test_loss': [1.0349013268947602,\n",
       "   0.6298431378602981,\n",
       "   0.5402841069549322,\n",
       "   0.5064284411817789,\n",
       "   0.4860883841663599,\n",
       "   0.49515478141605856,\n",
       "   0.44756900452077386,\n",
       "   0.43074901066720483,\n",
       "   0.4150885558128357,\n",
       "   0.3549237833917141,\n",
       "   0.28740826055407526,\n",
       "   0.24461577016860248,\n",
       "   0.22487336721271275,\n",
       "   0.24360474493354559,\n",
       "   0.23432610005140306]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6861892583500594,\n",
       "   0.37892855373211204,\n",
       "   0.3882111982349306,\n",
       "   0.34935376964043824,\n",
       "   0.32679467923007904,\n",
       "   0.32084062955807896,\n",
       "   0.301954476586543,\n",
       "   0.30964191764593124,\n",
       "   0.2933669139165431,\n",
       "   0.29052892078179865,\n",
       "   0.2921694733388722,\n",
       "   0.2939992489526048,\n",
       "   0.2917101137060672,\n",
       "   0.28611265544313935,\n",
       "   0.2781211663177237],\n",
       "  'running_test_loss': [0.24142108183354138,\n",
       "   0.25618310648947956,\n",
       "   0.23946640118956566,\n",
       "   0.21156201999634505,\n",
       "   0.1867855423130095,\n",
       "   0.17871728040277957,\n",
       "   0.15956570629030467,\n",
       "   0.16269923720508814,\n",
       "   0.1489649195410311,\n",
       "   0.1486835981346667,\n",
       "   0.1502771828137338,\n",
       "   0.1785228573717177,\n",
       "   0.19255685312673448,\n",
       "   0.14712032848969103,\n",
       "   0.15686895668506623]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6347677616495639,\n",
       "   0.3930604470334947,\n",
       "   0.3849768797587603,\n",
       "   0.3775501373130828,\n",
       "   0.3802400197833776,\n",
       "   0.3597905493341386,\n",
       "   0.36163367262110113,\n",
       "   0.3388719002250582,\n",
       "   0.3444671679381281,\n",
       "   0.3416298173461109,\n",
       "   0.3412930758995935,\n",
       "   0.31062948481645436,\n",
       "   0.3074612884270027,\n",
       "   0.31532224371097983,\n",
       "   0.29820398340933024],\n",
       "  'running_test_loss': [0.29065961558371783,\n",
       "   0.24915388248860837,\n",
       "   0.2407883022725582,\n",
       "   0.27116198759526017,\n",
       "   0.24705533105880023,\n",
       "   0.2168058579415083,\n",
       "   0.22096696980297564,\n",
       "   0.24782156644389033,\n",
       "   0.20210057551041247,\n",
       "   0.21129964796826242,\n",
       "   0.18873307570815087,\n",
       "   0.14916789969429373,\n",
       "   0.18450616730377079,\n",
       "   0.15582015374675393,\n",
       "   0.18786432513967155]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6610010384954512,\n",
       "   0.38942399304360154,\n",
       "   0.37279742860235277,\n",
       "   0.3473562813550234,\n",
       "   0.33049484443850813,\n",
       "   0.322959491237998,\n",
       "   0.3323447824083269,\n",
       "   0.3331943040061742,\n",
       "   0.32616429461166263,\n",
       "   0.32415023174136876,\n",
       "   0.32112149698659775,\n",
       "   0.3062371274409816,\n",
       "   0.31697571912780403,\n",
       "   0.31721612797584386,\n",
       "   0.3035840846132487],\n",
       "  'running_test_loss': [0.2740075200051069,\n",
       "   0.25964303854852916,\n",
       "   0.2220640143752098,\n",
       "   0.24861531872302295,\n",
       "   0.2473967290110886,\n",
       "   0.18339584682136775,\n",
       "   0.22111829046159984,\n",
       "   0.20711233984678984,\n",
       "   0.20797336066141725,\n",
       "   0.21172220626845956,\n",
       "   0.17306252056732774,\n",
       "   0.19121636547148227,\n",
       "   0.20565532766282557,\n",
       "   0.1911601086705923,\n",
       "   0.15527349334210158]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6202560563758016,\n",
       "   0.3771141107287258,\n",
       "   0.3718926051072776,\n",
       "   0.356952443998307,\n",
       "   0.36427701080683617,\n",
       "   0.356734684901312,\n",
       "   0.34897902970202266,\n",
       "   0.3486013050423935,\n",
       "   0.3490573417022824,\n",
       "   0.3394659363199025,\n",
       "   0.3272844740841538,\n",
       "   0.3265933624748141,\n",
       "   0.33023148490116,\n",
       "   0.30769360484555364,\n",
       "   0.30149158359505235],\n",
       "  'running_test_loss': [0.3008450034633279,\n",
       "   0.22642877969890832,\n",
       "   0.2143383350223303,\n",
       "   0.2566711025126278,\n",
       "   0.21307788837701083,\n",
       "   0.190556404273957,\n",
       "   0.2228194850496948,\n",
       "   0.19342359516769647,\n",
       "   0.205469617433846,\n",
       "   0.17264013338834047,\n",
       "   0.20208951156586408,\n",
       "   0.21839850813150405,\n",
       "   0.17607741452753545,\n",
       "   0.18090823607519269,\n",
       "   0.1604768210835755]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.4008027243614196,\n",
       "   1.093653653860092,\n",
       "   0.6757043049484491,\n",
       "   0.5641301830112934,\n",
       "   0.5425522841699422,\n",
       "   0.4924160754680634,\n",
       "   0.4613527927547693,\n",
       "   0.41652963249012825,\n",
       "   0.40869388383813204,\n",
       "   0.3849329357873648,\n",
       "   0.37942324672825634,\n",
       "   0.3841838823724538,\n",
       "   0.3762431774102151,\n",
       "   0.3649041846487671,\n",
       "   0.36085490002296866],\n",
       "  'running_test_loss': [1.3366003239154816,\n",
       "   0.7997823631763459,\n",
       "   0.5303654672205448,\n",
       "   0.47614887930452826,\n",
       "   0.412602221518755,\n",
       "   0.35829795733094216,\n",
       "   0.33378302086144684,\n",
       "   0.30699575126171114,\n",
       "   0.24874426197260618,\n",
       "   0.25875876408070325,\n",
       "   0.242499414421618,\n",
       "   0.22088078584522008,\n",
       "   0.2769226332753897,\n",
       "   0.2757237039878964,\n",
       "   0.27421141596511006]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.234854201376438,\n",
       "   0.830073921829462,\n",
       "   0.6539519769698381,\n",
       "   0.6197174754366279,\n",
       "   0.5905018381401896,\n",
       "   0.5740146706067025,\n",
       "   0.5284846497885883,\n",
       "   0.4708574953302741,\n",
       "   0.4356825090572238,\n",
       "   0.3912921188492328,\n",
       "   0.3807160963770002,\n",
       "   0.3897951308172196,\n",
       "   0.3721995076071471,\n",
       "   0.37780057040974496,\n",
       "   0.37391405264846983],\n",
       "  'running_test_loss': [0.974151693880558,\n",
       "   0.601930822879076,\n",
       "   0.5082311823964119,\n",
       "   0.4897452387958765,\n",
       "   0.466018680408597,\n",
       "   0.45565794125199316,\n",
       "   0.4028072270005941,\n",
       "   0.3404257807135582,\n",
       "   0.31006456129252913,\n",
       "   0.26218654569238425,\n",
       "   0.2802683899179101,\n",
       "   0.2746834635734558,\n",
       "   0.2609141732007265,\n",
       "   0.2322441354393959,\n",
       "   0.24552086744457483]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.388039181381464,\n",
       "   1.1211311960220336,\n",
       "   0.7326337534561753,\n",
       "   0.6151708067208529,\n",
       "   0.582676221653819,\n",
       "   0.5502377457730472,\n",
       "   0.5095599625445902,\n",
       "   0.46402405731379986,\n",
       "   0.4370219240617007,\n",
       "   0.41930467600934207,\n",
       "   0.3850439669564366,\n",
       "   0.38273000278510155,\n",
       "   0.3789677172526717,\n",
       "   0.35426449476741256,\n",
       "   0.3593669886235148],\n",
       "  'running_test_loss': [1.3029229813814163,\n",
       "   0.8473174580931664,\n",
       "   0.5483620010316372,\n",
       "   0.4790505187213421,\n",
       "   0.46157268054783346,\n",
       "   0.42886659808456895,\n",
       "   0.37217763133347037,\n",
       "   0.34050314843654633,\n",
       "   0.26965399004518986,\n",
       "   0.26689307048916816,\n",
       "   0.25603302750736473,\n",
       "   0.22636673603206872,\n",
       "   0.2583506923913956,\n",
       "   0.25958882974460723,\n",
       "   0.2390485080331564]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.044405015781522,\n",
       "   0.7199352012947202,\n",
       "   0.62143893443048,\n",
       "   0.5905323995649815,\n",
       "   0.5625939735211432,\n",
       "   0.530147823933512,\n",
       "   0.4828836704790592,\n",
       "   0.4366542783007026,\n",
       "   0.4144145588669926,\n",
       "   0.3954535271041095,\n",
       "   0.3741213194001466,\n",
       "   0.37955135189928113,\n",
       "   0.37513927878811953,\n",
       "   0.37844028702937066,\n",
       "   0.37722083570435644],\n",
       "  'running_test_loss': [0.8343349865078926,\n",
       "   0.5868571420013905,\n",
       "   0.5204540538787842,\n",
       "   0.48105154603719713,\n",
       "   0.4464816342294216,\n",
       "   0.38105009488761427,\n",
       "   0.3202943720668554,\n",
       "   0.303702799230814,\n",
       "   0.2793059838935733,\n",
       "   0.25436658181250094,\n",
       "   0.2646112038195133,\n",
       "   0.24061262223869562,\n",
       "   0.2603161755204201,\n",
       "   0.27779289580881594,\n",
       "   0.27719653155654667]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.5941753248870373,\n",
       "   0.395968262962997,\n",
       "   0.3973850300721824,\n",
       "   0.37918208898976447,\n",
       "   0.3743915204145014,\n",
       "   0.37558120662346484,\n",
       "   0.37212296766228975,\n",
       "   0.3655779991764575,\n",
       "   0.3392346902564168,\n",
       "   0.339360709739849,\n",
       "   0.328568696109578,\n",
       "   0.3327603588718921,\n",
       "   0.34050804541446267,\n",
       "   0.31290531100705266,\n",
       "   0.3211847949121147],\n",
       "  'running_test_loss': [0.31274292085319755,\n",
       "   0.28328272365033624,\n",
       "   0.2718403220549226,\n",
       "   0.28763439036905764,\n",
       "   0.2637165161035955,\n",
       "   0.25621023524552583,\n",
       "   0.23065935615450145,\n",
       "   0.1882622541859746,\n",
       "   0.17575027452781797,\n",
       "   0.17846154872328043,\n",
       "   0.16658221501857043,\n",
       "   0.18956931337714195,\n",
       "   0.17327149044722318,\n",
       "   0.17596736492589116,\n",
       "   0.17523359149694442]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6585992629639804,\n",
       "   0.40935389542020856,\n",
       "   0.4001348968222737,\n",
       "   0.38713144749403,\n",
       "   0.3723285855632275,\n",
       "   0.3705130492709577,\n",
       "   0.37514590789563956,\n",
       "   0.35654599814675747,\n",
       "   0.35778814061544834,\n",
       "   0.3595360379852355,\n",
       "   0.33913408960215746,\n",
       "   0.3531266542337835,\n",
       "   0.33628097153268754,\n",
       "   0.33683122583664954,\n",
       "   0.3360730080679059],\n",
       "  'running_test_loss': [0.2713844659924507,\n",
       "   0.2698519450798631,\n",
       "   0.226249695494771,\n",
       "   0.2509207197278738,\n",
       "   0.2249380700662732,\n",
       "   0.2524627097323537,\n",
       "   0.25832632709294556,\n",
       "   0.21743456654250623,\n",
       "   0.27301943600177764,\n",
       "   0.2335325400903821,\n",
       "   0.19247442558407785,\n",
       "   0.20090107765048743,\n",
       "   0.19495618510991336,\n",
       "   0.2071218934096396,\n",
       "   0.17842318955808878]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6135720416344702,\n",
       "   0.400861041136086,\n",
       "   0.37353624882176517,\n",
       "   0.3823595416639,\n",
       "   0.3707605060748756,\n",
       "   0.37205516738817096,\n",
       "   0.3619626191072166,\n",
       "   0.35929598652757705,\n",
       "   0.3733993785269558,\n",
       "   0.3581475968379527,\n",
       "   0.3510672824084759,\n",
       "   0.32861292594112457,\n",
       "   0.3377438650559634,\n",
       "   0.33241511137224733,\n",
       "   0.33193708064965904],\n",
       "  'running_test_loss': [0.24762107931077482,\n",
       "   0.2700660982728004,\n",
       "   0.22286588974297047,\n",
       "   0.21711413230746984,\n",
       "   0.2205919061601162,\n",
       "   0.24153217010200023,\n",
       "   0.19949516404420137,\n",
       "   0.2161686783283949,\n",
       "   0.21161753714084625,\n",
       "   0.22207233790308237,\n",
       "   0.20842694077640772,\n",
       "   0.19184507681056856,\n",
       "   0.1644627075828612,\n",
       "   0.2121682897955179,\n",
       "   0.21134197982028127]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.7143705149181188,\n",
       "   0.5004162121005357,\n",
       "   0.403273535547778,\n",
       "   0.3841605217102915,\n",
       "   0.3757069845311344,\n",
       "   0.3681702664401382,\n",
       "   0.36558744081296024,\n",
       "   0.37038360674865545,\n",
       "   0.35503370250575245,\n",
       "   0.34331783120520415,\n",
       "   0.31978165472857656,\n",
       "   0.3126197818759829,\n",
       "   0.3108735150098801,\n",
       "   0.3191484154108912,\n",
       "   0.32273861146532],\n",
       "  'running_test_loss': [0.45533682599663733,\n",
       "   0.31836656365543603,\n",
       "   0.2645054906606674,\n",
       "   0.2496595524251461,\n",
       "   0.2337599365785718,\n",
       "   0.21626380175352097,\n",
       "   0.22949764020740987,\n",
       "   0.21855397701263427,\n",
       "   0.1911281867325306,\n",
       "   0.18822116196155547,\n",
       "   0.2063943873718381,\n",
       "   0.16955070538446307,\n",
       "   0.1752882219851017,\n",
       "   0.18426376510411502,\n",
       "   0.1695624941214919]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2310719891637563,\n",
       "   0.8949097739160061,\n",
       "   0.706279420517385,\n",
       "   0.6528982686623931,\n",
       "   0.6262795183248818,\n",
       "   0.6091161389276385,\n",
       "   0.6014071859046817,\n",
       "   0.5977348085306585,\n",
       "   0.5888409474864602,\n",
       "   0.5803935960307718,\n",
       "   0.5792636323161423,\n",
       "   0.5663035232573748,\n",
       "   0.5586183662898838,\n",
       "   0.5464312960021198,\n",
       "   0.558823771160096],\n",
       "  'running_test_loss': [1.0722386309504508,\n",
       "   0.6942428220808506,\n",
       "   0.5785606713593006,\n",
       "   0.5421276699751616,\n",
       "   0.5200211629271507,\n",
       "   0.49436760127544405,\n",
       "   0.4905663388222456,\n",
       "   0.4592919749766588,\n",
       "   0.4836394712328911,\n",
       "   0.4762067165225744,\n",
       "   0.45931205809116366,\n",
       "   0.449442768022418,\n",
       "   0.42512876354157925,\n",
       "   0.44133104108273985,\n",
       "   0.42744456358253957]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.346714608222246,\n",
       "   1.099929915741086,\n",
       "   0.7988549137488008,\n",
       "   0.6315471795201302,\n",
       "   0.5550819589570165,\n",
       "   0.47615970220416787,\n",
       "   0.4306455205194652,\n",
       "   0.41291392538696525,\n",
       "   0.41258041294291614,\n",
       "   0.40689189855009317,\n",
       "   0.3989066381473094,\n",
       "   0.39050218666903674,\n",
       "   0.3961728725023568,\n",
       "   0.4105310770869255,\n",
       "   0.3947617721091956],\n",
       "  'running_test_loss': [1.2371832871437072,\n",
       "   0.8935176733136178,\n",
       "   0.6221606865525245,\n",
       "   0.48593376241624353,\n",
       "   0.3685979645699263,\n",
       "   0.28471241280436516,\n",
       "   0.2992053112387657,\n",
       "   0.2556950814649463,\n",
       "   0.2599777106195688,\n",
       "   0.25460207249969247,\n",
       "   0.23379285916686057,\n",
       "   0.28486005891114474,\n",
       "   0.2998161385953426,\n",
       "   0.2843454296886921,\n",
       "   0.23576206266880034]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.3712529715895654,\n",
       "   1.097216155603528,\n",
       "   0.7748259494453669,\n",
       "   0.6380768175795675,\n",
       "   0.6026442557573318,\n",
       "   0.581577050127089,\n",
       "   0.5380253356322646,\n",
       "   0.5160856422036886,\n",
       "   0.4911484574154019,\n",
       "   0.4500169161334634,\n",
       "   0.4452598407864571,\n",
       "   0.4264704549405724,\n",
       "   0.432466352628544,\n",
       "   0.4062459077406675,\n",
       "   0.4051489210687578],\n",
       "  'running_test_loss': [1.241156086921692,\n",
       "   0.8693907573819161,\n",
       "   0.5873277986049652,\n",
       "   0.5192564578354358,\n",
       "   0.46244170151650904,\n",
       "   0.46039322383701803,\n",
       "   0.3906247352063656,\n",
       "   0.3807433719187975,\n",
       "   0.3594094017148018,\n",
       "   0.31291356302797796,\n",
       "   0.3084937721863389,\n",
       "   0.27283614713698623,\n",
       "   0.2902072756364942,\n",
       "   0.2551923906430602,\n",
       "   0.24413357958197593]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.05,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2500297306478023,\n",
       "   0.8538454487547278,\n",
       "   0.659675774872303,\n",
       "   0.6322299286350608,\n",
       "   0.6003246561437845,\n",
       "   0.5731439277529716,\n",
       "   0.5445985095575452,\n",
       "   0.5220006939396262,\n",
       "   0.4761816956289113,\n",
       "   0.4435747756436467,\n",
       "   0.44448600750416517,\n",
       "   0.41879481543786823,\n",
       "   0.4107102917227894,\n",
       "   0.4175866433978081,\n",
       "   0.39970055454410613],\n",
       "  'running_test_loss': [1.0180727446079254,\n",
       "   0.6145704552531243,\n",
       "   0.5244641128182411,\n",
       "   0.5166933551430702,\n",
       "   0.4961756341904402,\n",
       "   0.44375854775309564,\n",
       "   0.3854574442654848,\n",
       "   0.33619434289634226,\n",
       "   0.30125781424343584,\n",
       "   0.30724410828202964,\n",
       "   0.2801044201478362,\n",
       "   0.2624846760928631,\n",
       "   0.30587909374386074,\n",
       "   0.28374820478260515,\n",
       "   0.2817619534209371]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.622273700479418,\n",
       "   0.44645701417699457,\n",
       "   0.4109566911682487,\n",
       "   0.37813820321112873,\n",
       "   0.37551676501519976,\n",
       "   0.3725292885862291,\n",
       "   0.37865549095906315,\n",
       "   0.3662122212443501,\n",
       "   0.35145750678144394,\n",
       "   0.3625010850932449,\n",
       "   0.3464741934742779,\n",
       "   0.35335118385963143,\n",
       "   0.33626548962667585,\n",
       "   0.36530321412719785,\n",
       "   0.35942286751233044],\n",
       "  'running_test_loss': [0.3655447541922331,\n",
       "   0.26955597270280124,\n",
       "   0.2773156211525202,\n",
       "   0.21893800608813763,\n",
       "   0.2262472788244486,\n",
       "   0.21868037287145853,\n",
       "   0.2222323389351368,\n",
       "   0.18791307117789985,\n",
       "   0.22396436043083667,\n",
       "   0.21410107519477606,\n",
       "   0.18794420920312405,\n",
       "   0.16792652752250434,\n",
       "   0.26941371653228996,\n",
       "   0.190910810418427,\n",
       "   0.21752696935087443]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6371436713635922,\n",
       "   0.4142002515401691,\n",
       "   0.3975251062773168,\n",
       "   0.39541479712352157,\n",
       "   0.3754505040962249,\n",
       "   0.38793423073366284,\n",
       "   0.3875290507264435,\n",
       "   0.37313822948373854,\n",
       "   0.3664853010699153,\n",
       "   0.37060196610167623,\n",
       "   0.3697875052224845,\n",
       "   0.366982438955456,\n",
       "   0.3731831828691065,\n",
       "   0.36191586846485735,\n",
       "   0.3652256574202329],\n",
       "  'running_test_loss': [0.26291137795895336,\n",
       "   0.2410689288377762,\n",
       "   0.24632794015109538,\n",
       "   0.24321065682917833,\n",
       "   0.22619997926056384,\n",
       "   0.248687961101532,\n",
       "   0.24930852249264718,\n",
       "   0.2244647772423923,\n",
       "   0.24604698576033115,\n",
       "   0.22886431869119406,\n",
       "   0.22842390563338996,\n",
       "   0.2378616101294756,\n",
       "   0.23992310237139464,\n",
       "   0.1992567305639386,\n",
       "   0.2154945906624198]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6416360050626099,\n",
       "   0.3979352396726608,\n",
       "   0.4026433699391782,\n",
       "   0.3786457985267043,\n",
       "   0.38003002997487784,\n",
       "   0.36914302257820963,\n",
       "   0.3643047218117863,\n",
       "   0.359891863213852,\n",
       "   0.34777474441565576,\n",
       "   0.3597319308016449,\n",
       "   0.36391873244196177,\n",
       "   0.36419766610488297,\n",
       "   0.3439294083137065,\n",
       "   0.34535320341587067,\n",
       "   0.35068160386756064],\n",
       "  'running_test_loss': [0.2726756888255477,\n",
       "   0.28389702271670103,\n",
       "   0.3092208767309785,\n",
       "   0.2749968487396836,\n",
       "   0.195633612498641,\n",
       "   0.23183427404612303,\n",
       "   0.2076042473502457,\n",
       "   0.23755456803366543,\n",
       "   0.20985696118324995,\n",
       "   0.24735767148435117,\n",
       "   0.29786334484815596,\n",
       "   0.25864847138524055,\n",
       "   0.21808034982532262,\n",
       "   0.245218593031168,\n",
       "   0.21840657426044344]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'running_classification_total_loss': [0.6215780194289983,\n",
       "   0.4070885793212801,\n",
       "   0.38881139347329735,\n",
       "   0.37738906007260087,\n",
       "   0.3708588083367795,\n",
       "   0.3932671122904867,\n",
       "   0.39288080741651354,\n",
       "   0.3783715580124408,\n",
       "   0.36343724831938745,\n",
       "   0.37222401160746815,\n",
       "   0.37715840032324194,\n",
       "   0.36602316120639444,\n",
       "   0.3538102082069963,\n",
       "   0.37041879538446665,\n",
       "   0.3483284713421017],\n",
       "  'running_test_loss': [0.26249430026859044,\n",
       "   0.245866996049881,\n",
       "   0.23276586420834064,\n",
       "   0.22391119845211505,\n",
       "   0.29088186208158734,\n",
       "   0.28408737801015377,\n",
       "   0.22819423720240592,\n",
       "   0.2275409984216094,\n",
       "   0.2388986759632826,\n",
       "   0.23567746087908745,\n",
       "   0.20704892683774234,\n",
       "   0.216560279391706,\n",
       "   0.22887237213551997,\n",
       "   0.2147071111574769,\n",
       "   0.20435692947357892]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 4,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [0.944195574298501,\n",
       "   0.7198190950229764,\n",
       "   0.6444742300361395,\n",
       "   0.5998685834556818,\n",
       "   0.550033163651824,\n",
       "   0.5145191733725369,\n",
       "   0.49325839256867765,\n",
       "   0.47944842869415877,\n",
       "   0.47052834160625934,\n",
       "   0.44985736507922414,\n",
       "   0.45989331051707266,\n",
       "   0.45159714192152023,\n",
       "   0.4477062572352588,\n",
       "   0.45223652871325615,\n",
       "   0.4298853574041277],\n",
       "  'running_test_loss': [0.7368543037772178,\n",
       "   0.5675580452382565,\n",
       "   0.512179341390729,\n",
       "   0.4264769133925438,\n",
       "   0.36357658796012404,\n",
       "   0.28497112162411214,\n",
       "   0.29430983822792767,\n",
       "   0.27147532436996696,\n",
       "   0.288444363810122,\n",
       "   0.27657024063169955,\n",
       "   0.3092096653208137,\n",
       "   0.2955213027074933,\n",
       "   0.3027883941307664,\n",
       "   0.2749289412423968,\n",
       "   0.2567849933728576]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 8,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.0050230257958175,\n",
       "   0.7449267405644059,\n",
       "   0.6628237999230623,\n",
       "   0.624696438126266,\n",
       "   0.5832590683549642,\n",
       "   0.541698071602732,\n",
       "   0.5099200058542191,\n",
       "   0.47603501779958607,\n",
       "   0.45017898447811605,\n",
       "   0.4185623636096716,\n",
       "   0.40766806819476187,\n",
       "   0.3982966619264334,\n",
       "   0.39505588399246333,\n",
       "   0.4174157859571278,\n",
       "   0.3969067806936801],\n",
       "  'running_test_loss': [0.7654707911610603,\n",
       "   0.5783376777172089,\n",
       "   0.5348825956881046,\n",
       "   0.46745857954025266,\n",
       "   0.41065895043313505,\n",
       "   0.370103257894516,\n",
       "   0.33483113564550876,\n",
       "   0.27669455491006373,\n",
       "   0.2526011038571596,\n",
       "   0.2894479880481958,\n",
       "   0.24881019938737153,\n",
       "   0.26701591473072767,\n",
       "   0.23767039500176906,\n",
       "   0.3068974695727229,\n",
       "   0.24561105109751225]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 16,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.2779371185600759,\n",
       "   0.833873036056757,\n",
       "   0.6744949886947871,\n",
       "   0.647338716648519,\n",
       "   0.6266364949941635,\n",
       "   0.6124103609472513,\n",
       "   0.5868550404161215,\n",
       "   0.5658083162829279,\n",
       "   0.5447011509910226,\n",
       "   0.521886469963938,\n",
       "   0.5146146390214562,\n",
       "   0.5023456513136625,\n",
       "   0.4950284921377897,\n",
       "   0.4942581333592534,\n",
       "   0.47511171236634253],\n",
       "  'running_test_loss': [1.0385677582025528,\n",
       "   0.5916939018666745,\n",
       "   0.5338716918230056,\n",
       "   0.5222039890289306,\n",
       "   0.492219599634409,\n",
       "   0.4541948872804642,\n",
       "   0.4107812306284904,\n",
       "   0.4050106416642666,\n",
       "   0.3840909909456968,\n",
       "   0.3556960768252611,\n",
       "   0.32520023215562105,\n",
       "   0.35817145712673665,\n",
       "   0.3329541475698352,\n",
       "   0.3352207591757178,\n",
       "   0.3303268238529563]},\n",
       " {'bi_mamba_stacks': 4,\n",
       "  'n_layers': 32,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.0001,\n",
       "  'running_classification_total_loss': [1.4234153412282466,\n",
       "   1.0779865100979804,\n",
       "   0.7345944711193443,\n",
       "   0.5799889354780317,\n",
       "   0.5427062014117837,\n",
       "   0.511948409602046,\n",
       "   0.4908605514280498,\n",
       "   0.4763180610537529,\n",
       "   0.45407289985567334,\n",
       "   0.45382451221346853,\n",
       "   0.4281958895176649,\n",
       "   0.43778717003762724,\n",
       "   0.4315403402969241,\n",
       "   0.4250587148591876,\n",
       "   0.41818552155047656],\n",
       "  'running_test_loss': [1.2540664875507355,\n",
       "   0.8231302958726883,\n",
       "   0.5258228604495525,\n",
       "   0.4434182505309582,\n",
       "   0.38655028358101845,\n",
       "   0.36063225150108336,\n",
       "   0.32031305469572546,\n",
       "   0.32206182669848205,\n",
       "   0.3158099499717355,\n",
       "   0.2894312445446849,\n",
       "   0.2993525392189622,\n",
       "   0.2812087841331959,\n",
       "   0.29842272602021697,\n",
       "   0.25270790707319973,\n",
       "   0.2843308846652508]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f35c0c-792e-46a4-a818-0b29ba0b2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5c667c-d503-4754-8335-a38e62ed267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('8ksample_2ktest_20part_T200_30epoch_classification_only.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d0668-ca4c-4c43-9f4a-dfadc0b248ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
